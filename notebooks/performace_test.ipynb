{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['/mnt/hdd2/transformer-entropy-ids/notebooks', '/home/tiendat/miniconda3/envs/piptorchtf/lib/python39.zip', '/home/tiendat/miniconda3/envs/piptorchtf/lib/python3.9', '/home/tiendat/miniconda3/envs/piptorchtf/lib/python3.9/lib-dynload', '', '/home/tiendat/miniconda3/envs/piptorchtf/lib/python3.9/site-packages', '../', '../']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from dataPreprocess import DatasetPreprocess\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, classification_report, confusion_matrix\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion(label_y, pre_y, path):\n",
    "    confusion = confusion_matrix(label_y, pre_y)\n",
    "    print(confusion)\n",
    "\n",
    "def write_result(label_y, pre_y, classes_num):\n",
    "    if classes_num > 2:\n",
    "        accuracy = accuracy_score(label_y, pre_y)\n",
    "        macro_precision = precision_score(label_y, pre_y, average='macro')\n",
    "        macro_recall = recall_score(label_y, pre_y, average='macro')\n",
    "        macro_f1 = f1_score(label_y, pre_y, average='macro')\n",
    "        micro_precision = precision_score(label_y, pre_y, average='micro')\n",
    "        micro_recall = recall_score(label_y, pre_y, average='micro')\n",
    "        micro_f1 = f1_score(label_y, pre_y, average='micro')\n",
    "        print('  -- test result: ')\n",
    "        print('    -- accuracy: ', accuracy)\n",
    "        print('    -- macro precision: ', macro_precision)\n",
    "        print('    -- macro recall: ', macro_recall)\n",
    "        print('    -- macro f1 score: ', macro_f1)\n",
    "        print('    -- micro precision: ', micro_precision)\n",
    "        print('    -- micro recall: ', micro_recall)\n",
    "        print('    -- micro f1 score: ', micro_f1)\n",
    "        report = classification_report(label_y, pre_y)\n",
    "        print(report)\n",
    "    else:\n",
    "        accuracy = accuracy_score(label_y, pre_y)\n",
    "        precision = precision_score(label_y, pre_y)\n",
    "        recall = recall_score(label_y, pre_y)\n",
    "        f1 = f1_score(label_y, pre_y)\n",
    "        print('  -- test result: ')\n",
    "        print('    -- accuracy: ', accuracy)\n",
    "        print('    -- recall: ', recall)\n",
    "        print('    -- precision: ', precision)\n",
    "        print('    -- f1 score: ', f1)\n",
    "        report = classification_report(label_y, pre_y)\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_name = 'Transformer'\n",
    "        self.slide_window = 1\n",
    "        self.slsum_count = 8 #int(math.pow(16, self.slide_window))  # 滑动窗口计数的特征的长度 n-gram?\n",
    "        self.dnn_out_d = 8 # 经过DNN后的滑动窗口计数特征的维度 Dimensions of sliding window count features after DNN 8\n",
    "        self.head_dnn_out_d = 32 \n",
    "        self.d_model = self.dnn_out_d + self.head_dnn_out_d # transformer的输入的特征的维度, dnn_out_d + 包头长度 The dimension of the input feature of the transformer, dnn_out_d + header length\n",
    "        self.pad_size = 29\n",
    "        self.window_size = 29\n",
    "        self.max_time_position = 10000\n",
    "        self.nhead = 5 # ori: 5\n",
    "        self.num_layers = 5\n",
    "        self.gran = 1e-6\n",
    "        self.log_e = 2\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.classes_num = 5 \n",
    "        self.batch_size = 10\n",
    "        self.epoch_num = 20\n",
    "        self.lr = 0.00001 #0.00001 learning rate \n",
    "        self.train_pro = 0.7  # 训练集比例 Ratio of training set\n",
    "\n",
    "        self.root_dir = '../data/Processed/TFRecord_w29_s29/1/'\n",
    "        self.model_save_path = '../model/' + self.model_name + '/'\n",
    "        if not os.path.exists(self.model_save_path):\n",
    "            os.mkdir(self.model_save_path)\n",
    "        self.result_file = '/mnt/hdd2/transformer-entropy-ids/result/trans8_performance.txt'\n",
    "\n",
    "        self.isload_model = False  # 是否加载模型继续训练 Whether to load the model and continue training\n",
    "        self.start_epoch = 18  # 加载的模型的epoch The epoch of the loaded model\n",
    "        # self.model_path = '../model/' + self.model_name + '/' + self.model_name + '_model_' + str(self.start_epoch) + '.pth'  # 要使用的模型的路径 path to the model to use\n",
    "        self.model_path = '../model/Transformer/best_model.pth'\n",
    "        \n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, d_in, d_out):  # config.slsum_count, config.dnn_out_d\n",
    "        super(DNN, self).__init__()\n",
    "        self.l1 = nn.Linear(d_in, 128)\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('x: ', x.numpy()[0])\n",
    "        out = F.relu(self.l1(x))\n",
    "        out = F.relu(self.l2(out))\n",
    "        out = F.relu(self.l3(out))\n",
    "        # print('dnn out: ', out.detach().numpy()[0])\n",
    "        return out\n",
    "\n",
    "class Time_Positional_Encoding(nn.Module):\n",
    "    def __init__(self, embed, max_time_position, device):\n",
    "        super(Time_Positional_Encoding, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, time_position):\n",
    "        out = x.permute(1, 0, 2)\n",
    "        out = out + nn.Parameter(time_position, requires_grad=False).to(self.device)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        return out\n",
    "\n",
    "class MyTrans(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MyTrans, self).__init__()\n",
    "        self.dnn = DNN(config.slsum_count, config.dnn_out_d).to(config.device)\n",
    "        self.head_dnn = DNN(4, config.head_dnn_out_d).to(config.device)\n",
    "        self.position_embedding = Time_Positional_Encoding(config.d_model, config.max_time_position, config.device).to(config.device)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=config.d_model, nhead=config.nhead).to(config.device)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=config.num_layers).to(config.device)\n",
    "        self.fc = nn.Linear(config.d_model, config.classes_num).to(config.device)\n",
    "        self.pad_size = config.pad_size\n",
    "        self.dnn_out_d = config.dnn_out_d\n",
    "        self.head_dnn_out_d = config.head_dnn_out_d\n",
    "\n",
    "    def forward(self, header, sl_sum, mask, time_position):\n",
    "        dnn_out = torch.empty((sl_sum.shape[0], self.dnn_out_d, 0)).to(config.device)\n",
    "\n",
    "        for i in range(self.pad_size):\n",
    "            tmp = self.dnn(sl_sum[:, i, :]).unsqueeze(2)\n",
    "            dnn_out = torch.concat((dnn_out, tmp), dim=2)\n",
    "        dnn_out = dnn_out.permute(0, 2, 1)\n",
    "\n",
    "        head_dnn_out = torch.empty((header.shape[0], self.head_dnn_out_d, 0)).to(config.device)\n",
    "        for i in range(self.pad_size):\n",
    "            tmp = self.head_dnn(header[:, i, :]).unsqueeze(2)\n",
    "            head_dnn_out = torch.concat((head_dnn_out, tmp), dim=2)\n",
    "        head_dnn_out = head_dnn_out.permute(0, 2, 1)\n",
    "\n",
    "        x = torch.concat((head_dnn_out, dnn_out), dim=2).permute(1, 0, 2)\n",
    "\n",
    "        out = self.position_embedding(x, time_position)\n",
    "        out = self.transformer_encoder(out, src_key_padding_mask=mask)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = torch.sum(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "../model/Transformer/Transformer_model_18.pth\n",
      "finish load data\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print(config.device)\n",
    "print(config.model_path)\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "test_dataset = DatasetPreprocess(config.root_dir, config.window_size, config.pad_size, config.d_model, config.max_time_position, config.gran, config.log_e, is_train=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=config.batch_size)\n",
    "print('finish load data')\n",
    "\n",
    "model = torch.load(config.model_path)\n",
    "print(\"Model loaded\")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(config.device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -- test result: \n",
      "    -- accuracy:  1.0\n",
      "    -- macro precision:  1.0\n",
      "    -- macro recall:  1.0\n",
      "    -- macro f1 score:  1.0\n",
      "    -- micro precision:  1.0\n",
      "    -- micro recall:  1.0\n",
      "    -- micro f1 score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    105833\n",
      "         1.0       1.00      1.00      1.00     11236\n",
      "         2.0       1.00      1.00      1.00     13346\n",
      "         3.0       1.00      1.00      1.00     19585\n",
      "         4.0       1.00      1.00      1.00     21412\n",
      "\n",
      "    accuracy                           1.00    171412\n",
      "   macro avg       1.00      1.00      1.00    171412\n",
      "weighted avg       1.00      1.00      1.00    171412\n",
      "\n",
      "[[105833      0      0      0      0]\n",
      " [     0  11236      0      0      0]\n",
      " [     0      0  13346      0      0]\n",
      " [     0      0      0  19585      0]\n",
      " [     0      0      0      0  21412]]\n"
     ]
    }
   ],
   "source": [
    "label_y = []\n",
    "pre_y = []\n",
    "timeCalc = [] \n",
    "with torch.no_grad():\n",
    "    for j, test_sample_batch in enumerate(test_loader):\n",
    "        start_time = time.time()\n",
    "        test_header = test_sample_batch['header'].type(torch.FloatTensor).to(config.device)\n",
    "        test_sl_sum = test_sample_batch['payload'].type(torch.FloatTensor).to(config.device)\n",
    "        test_mask = test_sample_batch['mask'].to(config.device)\n",
    "        test_label = test_sample_batch['label'].to(config.device)\n",
    "        test_time_position = test_sample_batch['time'].to(config.device)\n",
    "            \n",
    "        \n",
    "        test_out = model(test_header, test_sl_sum, test_mask, test_time_position)\n",
    "\n",
    "        pre = torch.max(test_out, 1)[1].cpu().numpy()\n",
    "        pre_y = np.concatenate([pre_y, pre], 0)\n",
    "        label_y = np.concatenate([label_y, test_label.cpu().numpy()], 0)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        timeCalc.append(execution_time)\n",
    "    write_result(label_y, pre_y, config.classes_num)\n",
    "    draw_confusion(label_y, pre_y, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.012494143687528513 seconds\n"
     ]
    }
   ],
   "source": [
    "def calculate_average(arr):\n",
    "    if not arr:\n",
    "        raise ValueError(\"Input array is empty. Cannot calculate the average.\")\n",
    "    \n",
    "    total = sum(arr)\n",
    "    average = total / len(arr)\n",
    "    return average\n",
    "print(\"Execution time:\", calculate_average(timeCalc), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001251697540283203\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        a = i + j\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piptorchtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
