{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tiendat/transformer-entropy-ids/notebooks', '/home/tiendat/miniconda3/envs/torchtf/lib/python39.zip', '/home/tiendat/miniconda3/envs/torchtf/lib/python3.9', '/home/tiendat/miniconda3/envs/torchtf/lib/python3.9/lib-dynload', '', '/home/tiendat/miniconda3/envs/torchtf/lib/python3.9/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import argparse\n",
    "from dataPreprocess import DatasetPreprocess\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, classification_report, confusion_matrix\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion(label_y, pre_y, path):\n",
    "    confusion = confusion_matrix(label_y, pre_y)\n",
    "    print(confusion)\n",
    "    return confusion\n",
    "\n",
    "def write_result(label_y, pre_y, classes_num):\n",
    "    if classes_num > 2:\n",
    "        accuracy = accuracy_score(label_y, pre_y)\n",
    "        macro_precision = precision_score(label_y, pre_y, average='macro')\n",
    "        macro_recall = recall_score(label_y, pre_y, average='macro')\n",
    "        macro_f1 = f1_score(label_y, pre_y, average='macro')\n",
    "        micro_precision = precision_score(label_y, pre_y, average='micro')\n",
    "        micro_recall = recall_score(label_y, pre_y, average='micro')\n",
    "        micro_f1 = f1_score(label_y, pre_y, average='micro')\n",
    "        print('  -- test result: ')\n",
    "        print('    -- accuracy: ', accuracy)\n",
    "        print('    -- macro precision: ', macro_precision)\n",
    "        print('    -- macro recall: ', macro_recall)\n",
    "        print('    -- macro f1 score: ', macro_f1)\n",
    "        print('    -- micro precision: ', micro_precision)\n",
    "        print('    -- micro recall: ', micro_recall)\n",
    "        print('    -- micro f1 score: ', micro_f1)\n",
    "        report = classification_report(label_y, pre_y)\n",
    "        print(report)\n",
    "    else:\n",
    "        accuracy = accuracy_score(label_y, pre_y)\n",
    "        precision = precision_score(label_y, pre_y)\n",
    "        recall = recall_score(label_y, pre_y)\n",
    "        f1 = f1_score(label_y, pre_y)\n",
    "        print('  -- test result: ')\n",
    "        print('    -- accuracy: ', accuracy)\n",
    "        print('    -- recall: ', recall)\n",
    "        print('    -- precision: ', precision)\n",
    "        print('    -- f1 score: ', f1)\n",
    "        report = classification_report(label_y, pre_y)\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2522242971.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "#================================================================\n",
    "root_dir = \"../road/predict_fab_multi/TFRecord_w15_s15/1/\"\n",
    "window_size = 15\n",
    "d_model = 12\n",
    "max_time_position = 10000\n",
    "gran = 1e-6\n",
    "log_e = 2\n",
    "batch_size = 10\n",
    "\n",
    "train_dataset = DatasetPreprocess(root_dir, window_size, window_size, d_model, max_time_position, gran, log_e, is_train=True)\n",
    "test_dataset = DatasetPreprocess(root_dir, window_size,window_size, d_model, max_time_position, gran, log_e, is_train=False)\n",
    "\n",
    "\n",
    "print(\"TRAIN SIZE:\", len(train_dataset), \" TEST SIZE:\", len(test_dataset), \" SIZE:\", len(train_dataset)+len(test_dataset), \" TRAIN RATIO:\", round(len(train_dataset)/(len(train_dataset)+len(test_dataset))*100), \"%\")\n",
    "\n",
    "# 2 DataLoader? \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "print('finish load data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, args):\n",
    "        self.model_name = 'IDS-Transformer_' + args.type\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.payload_size = 8 \n",
    "            \n",
    "        if args.mode == \"ae\":\n",
    "            self.mode = args.mode\n",
    "            self.dout_payload = 7 \n",
    "            self.dout_header = 3 \n",
    "            self.d_model = self.dout_payload + self.dout_header # dimension input of transformer encoder\n",
    "            self.nhead = 10 # ori: 5\n",
    "        elif args.mode == \"dnn\":\n",
    "            self.mode = args.mode\n",
    "            self.dout_payload = 32\n",
    "            self.dout_header = 8 \n",
    "            self.d_model = self.dout_payload + self.dout_header \n",
    "            self.nhead = 5 # ori: 5\n",
    "        elif args.mode == \"cb\":\n",
    "            self.mode = args.mode\n",
    "            self.dout_mess = 10\n",
    "            self.d_model = self.dout_mess\n",
    "            self.nhead = 10 # ori: 5\n",
    "        else:\n",
    "            self.mode = args.mode\n",
    "            self.dout_mess = 12\n",
    "            self.d_model = self.dout_mess\n",
    "            self.nhead = 6 # ori: 5\n",
    "        \n",
    "        self.tse = args.tse\n",
    "        self.pad_size = args.window_size # 15\n",
    "        self.window_size =  args.window_size # 15\n",
    "        self.max_time_position = 10000\n",
    "        self.num_layers = 6\n",
    "        self.gran = 1e-6\n",
    "        self.log_e = 2\n",
    "        \n",
    "        if args.type == 'chd':\n",
    "            self.classes_num = 5\n",
    "        elif args.type == 'road_mas':\n",
    "            self.classes_num = 6\n",
    "        else: # road_fab\n",
    "            self.classes_num = 7 \n",
    "        \n",
    "            \n",
    "        self.batch_size = args.batch_size\n",
    "        self.epoch_num = args.epoch\n",
    "        self.lr = args.lr #0.00001 learning rate \n",
    "        self.root_dir = args.indir\n",
    "        \n",
    "        # self.root_dir = './data/Processed/TFRecord_w29_s29/2/'\n",
    "        # self.root_dir = './road/predict_fab_multi/TFRecord_w15_s15/1/'\n",
    "        # self.root_dir = './road/predict_mas/TFRecord_w15_s15/4/'\n",
    "        self.model_save_path = '../model/' + self.model_name + '/'\n",
    "        if not os.path.exists(self.model_save_path):\n",
    "            os.mkdir(self.model_save_path)\n",
    "        self.result_file = '/home/tiendat/transformer-entropy-ids/result/trans8_performance.txt'\n",
    "\n",
    "        self.isload_model = False  \n",
    "        self.start_epoch = 24  # The epoch of the loaded model\n",
    "        self.model_path = 'model/' + self.model_name + '/' + self.model_name + '_model_' + str(self.start_epoch) + '.pth' \n",
    "\n",
    "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor\n",
    "    \n",
    "class Autoencoder1D(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Autoencoder1D, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return F.relu(x)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, d_in, d_out):  # config.payload_size, config.dout_payload\n",
    "        super(DNN, self).__init__()\n",
    "        self.l1 = nn.Linear(d_in, 128)\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('x: ', x.cpu().numpy()[0])\n",
    "        out = F.relu(self.l1(x))\n",
    "        out = F.relu(self.l2(out))\n",
    "        out = F.relu(self.l3(out))\n",
    "        #print('dnn out: ', out.cpu().detach().numpy()[0])\n",
    "        return out\n",
    "\n",
    "class Time_Positional_Encoding(nn.Module):\n",
    "    def __init__(self, embed, max_time_position, device):\n",
    "        super(Time_Positional_Encoding, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, time_position):\n",
    "        out = x.permute(1, 0, 2)\n",
    "        out = out + nn.Parameter(time_position, requires_grad=False).to(self.device)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        return out\n",
    "    \n",
    "class TransformerPredictor(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TransformerPredictor, self).__init__()\n",
    "        \n",
    "        self.ae = Autoencoder1D(12, config.dout_mess).to(config.device)\n",
    "        self.pad_size = config.pad_size\n",
    "        \n",
    "        self.position_embedding = Time_Positional_Encoding(config.d_model, config.max_time_position, config.device).to(config.device)\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=config.d_model, nhead=config.nhead).to(config.device)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=config.num_layers).to(config.device)\n",
    "        self.fc = nn.Linear(config.d_model, config.classes_num).to(config.device)\n",
    "        \n",
    "    def forward(self, header, sl_sum, mask, time_position):\n",
    "        x = torch.concat((header, sl_sum), dim=-1)\n",
    "        ae_out = torch.empty((x.shape[0], 10, 0)).to(config.device)\n",
    "        for i in range(self.pad_size):\n",
    "            tmp = self.ae(x[:, i, :]).unsqueeze(2)\n",
    "            ae_out = torch.concat((ae_out, tmp), dim=2)\n",
    "        x = ae_out.permute(2, 0, 1)\n",
    "            \n",
    "        out = self.position_embedding(x, time_position)\n",
    "            \n",
    "        out = self.transformer_encoder(out, src_key_padding_mask=mask)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = torch.sum(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    indir=\"\",\n",
    "    window_size=15,\n",
    "    type=\"chd\",\n",
    "    epoch=200,\n",
    "    batch_size=32,\n",
    "    lr=0.0001,\n",
    "    mode=\"cb\",\n",
    "    tse=True\n",
    ")\n",
    "\n",
    "config = Config(args)\n",
    "model = TransformerPredictor(config)\n",
    "start_epoch = -1\n",
    "loss_func = nn.CrossEntropyLoss().to(config.device)\n",
    "opt = optim.Adam(model.parameters(), lr=config.lr)\n",
    "lr_scheduler = CosineWarmupScheduler(opt, warmup=500, max_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# Assuming 'inputs' is your input data\n",
    "inputs = [torch.randn(10, 15, 4), torch.randn(10, 15, 8), torch.randn(10, 15), torch.randn(10, 15, 12)]\n",
    "\n",
    "# Move the model and inputs to the same device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "inputs = [i.to(device) for i in inputs]\n",
    "\n",
    "# Make sure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Warm up (for more accurate timing)\n",
    "with torch.no_grad():\n",
    "    _ = model(*inputs)\n",
    "\n",
    "# Time the inference\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    _ = model(*inputs)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Inference time: {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Time_Positional_Encoding: 1-1               [15, 10, 12]              --\n",
      "├─TransformerEncoder: 1-2                     [15, 10, 12]              --\n",
      "|    └─ModuleList: 2                          []                        --\n",
      "|    |    └─TransformerEncoderLayer: 3-1      [15, 10, 12]              51,884\n",
      "|    |    └─TransformerEncoderLayer: 3-2      [15, 10, 12]              51,884\n",
      "|    |    └─TransformerEncoderLayer: 3-3      [15, 10, 12]              51,884\n",
      "|    |    └─TransformerEncoderLayer: 3-4      [15, 10, 12]              51,884\n",
      "|    |    └─TransformerEncoderLayer: 3-5      [15, 10, 12]              51,884\n",
      "├─Linear: 1-3                                 [10, 7]                   91\n",
      "===============================================================================================\n",
      "Total params: 259,511\n",
      "Trainable params: 259,511\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.75\n",
      "===============================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.93\n",
      "Params size (MB): 0.99\n",
      "Estimated Total Size (MB): 12.93\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Time_Positional_Encoding: 1-1               [15, 10, 12]              --\n",
       "├─TransformerEncoder: 1-2                     [15, 10, 12]              --\n",
       "|    └─ModuleList: 2                          []                        --\n",
       "|    |    └─TransformerEncoderLayer: 3-1      [15, 10, 12]              51,884\n",
       "|    |    └─TransformerEncoderLayer: 3-2      [15, 10, 12]              51,884\n",
       "|    |    └─TransformerEncoderLayer: 3-3      [15, 10, 12]              51,884\n",
       "|    |    └─TransformerEncoderLayer: 3-4      [15, 10, 12]              51,884\n",
       "|    |    └─TransformerEncoderLayer: 3-5      [15, 10, 12]              51,884\n",
       "├─Linear: 1-3                                 [10, 7]                   91\n",
       "===============================================================================================\n",
       "Total params: 259,511\n",
       "Trainable params: 259,511\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.75\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 11.93\n",
       "Params size (MB): 0.99\n",
       "Estimated Total Size (MB): 12.93\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [(10, 15, 4), (10, 15, 8), (10, 15,), (10, 15, 12)], batch_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "MACs (G):  37.0949\n",
      "Params (M):  0.259517\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "x = torch.rand((10, 15, 4)).to(config.device)\n",
    "y = torch.rand((10, 15, 8)).to(config.device)\n",
    "z = torch.rand((10, 15,)).to(config.device)\n",
    "a = torch.rand((10, 15, 10)).to(config.device)\n",
    "\n",
    "macs, params = profile(model, inputs=[x, y, z, a])\n",
    "print('MACs (G): ', macs/1000**2)\n",
    "print('Params (M): ', params/1000**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch  0\n",
      "torch.Size([10, 15, 4])\n",
      "torch.Size([10, 15, 8])\n",
      "torch.Size([10, 15])\n",
      "torch.Size([10, 15, 12])\n",
      "torch.Size([15, 10, 12])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     lr_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     aa\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# test\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m label_y \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch + 1, config.epoch_num):\n",
    "        fin = open(config.result_file, 'a')\n",
    "        print('--- epoch ', epoch)\n",
    "        fin.write('-- epoch ' + str(epoch) + '\\n')\n",
    "        for i, sample_batch in enumerate(train_loader):\n",
    "            batch_header = sample_batch['header'].type(torch.FloatTensor).to(config.device)\n",
    "            batch_payload = sample_batch['payload'].type(torch.FloatTensor).to(config.device)\n",
    "            batch_mask = sample_batch['mask'].to(config.device)\n",
    "            batch_label = sample_batch['label'].to(config.device)\n",
    "            batch_time_position = sample_batch['time'].to(config.device)\n",
    "            \n",
    "            out = model(batch_header, batch_payload, batch_mask, batch_time_position)\n",
    "            loss = loss_func(out, batch_label)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            lr_scheduler.step()\n",
    "            aa\n",
    "        # test\n",
    "        label_y = []\n",
    "        pre_y = []\n",
    "        with torch.no_grad():\n",
    "            for j, test_sample_batch in enumerate(test_loader):\n",
    "                test_header = test_sample_batch['header'].type(torch.FloatTensor).to(config.device)\n",
    "                test_payload = test_sample_batch['payload'].type(torch.FloatTensor).to(config.device)\n",
    "                test_mask = test_sample_batch['mask'].to(config.device)\n",
    "                test_label = test_sample_batch['label'].to(config.device)\n",
    "                test_time_position = test_sample_batch['time'].to(config.device)\n",
    "                \n",
    "                test_out = model(test_header, test_payload, test_mask, test_time_position)\n",
    "\n",
    "                pre = torch.max(test_out, 1)[1].cpu().numpy()\n",
    "                \n",
    "                pre_y = np.concatenate([pre_y, pre], 0)\n",
    "                label_y = np.concatenate([label_y, test_label.cpu().numpy()], 0)\n",
    "            write_result(label_y, pre_y, config.classes_num)\n",
    "            draw_confusion(label_y, pre_y, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(confusion_matrix):\n",
    "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "    fnr = fn/(tp + fn)\n",
    "    accu = (tp + tn) / (tp + tn + fp + fn)\n",
    "    err = (fn + fp) / (tp + tn + fp + fn)\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = 1 - fnr\n",
    "    f1score = (2 * precision * recall) / (precision + recall)\n",
    "    print(tn, fp)\n",
    "    print(fn, tp)\n",
    "    print('Accuracy: ', accu)\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 score: ', f1score)\n",
    "    print('Error rate: ', err)\n",
    "    print('False negative rate: ', fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32361 430\n",
      "2 52908\n",
      "Accuracy:  0.9949592186788953\n",
      "Precision:  0.9919382054070269\n",
      "Recall:  0.9999621999621999\n",
      "F1 score:  0.9959340411113621\n",
      "Error rate:  0.0050407813211047715\n",
      "False negative rate:  3.78000378000378e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate(np.array([[32361,430],[2,52908]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draw_confusion(label_y, pre_y, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m summary(model, [(\u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m4\u001b[39m), (\u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m8\u001b[39m), (\u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m,), (\u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m12\u001b[39m)], batch_dim\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Data for confusion matrix\n",
    "confusion_matrix_chd = np.array([[150833,      0,      0,      0,      0],\n",
    "                             [     0,  11236,      0,      0,      0],\n",
    "                             [     0,      0,  13346,      0,      0],\n",
    "                             [     0,      0,      0,  19585,      0],\n",
    "                             [     0,      0,      0,      0,  21412]])\n",
    "confusion_matrix_chd1 = np.array([[150833,      0,      0,      0,      0],\n",
    "                             [     12,  11224,      0,      0,      0],\n",
    "                             [     0,      0,  13336,      10,      0],\n",
    "                             [     13,      0,      0,  19572,      0],\n",
    "                             [     0,      2,      0,      0,  21410]])\n",
    "\n",
    "confusion_matrix_2 = np.array([\n",
    "    [15102, 0, 0, 1, 8, 0, 0],\n",
    "    [0, 9, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 12, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 2288, 0, 0, 0],\n",
    "    [2, 0, 0, 0, 1689, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1071, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1006]\n",
    "])\n",
    "\n",
    "cm_mas = np.array([\n",
    "    [15102,0,0,0,0,0],\n",
    "    [0,9,0,0,0,0],\n",
    "    [0,0,2250,0,0,0],\n",
    "    [0,0,0,1587,0,0],\n",
    "    [0,0,0,0,1051,0],\n",
    "    [0,0,0,0,0,990]\n",
    "])\n",
    "\n",
    "# Labels for classes\n",
    "labels = [\"Normal\", \"DoS\", \"Fuzz\", \"Gear\", \"RPM\"]\n",
    "\n",
    "labelss = [\"Normal\", \"Attack\"]\n",
    "labelsss = ['Normal', 'MEC', 'Fuzzing', 'MS', \n",
    "              'RLOn', 'RLOff', 'CS']\n",
    "labels_mas = ['Normal', 'MEC', 'MS', \n",
    "              'RLOn', 'RLOff', 'CS']\n",
    "cm = np.array([[14394, 0],\n",
    "               [0, 6448]])\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(25,11))\n",
    "\n",
    "sns.heatmap(confusion_matrix_chd, annot=True, fmt=\"d\", cmap=\"Greys\", xticklabels=labels, yticklabels=labels, annot_kws={\"size\": 16}, ax=axs[0])\n",
    "axs[0].tick_params(labelsize=18)\n",
    "axs[0].set_ylabel('True Label', fontsize=20, labelpad=15)\n",
    "axs[0].set_xlabel('Predicted Label', fontsize=20, labelpad=15)\n",
    "axs[0].set_title('Ours', fontsize=20)\n",
    "\n",
    "sns.heatmap(confusion_matrix_chd1, annot=True, fmt=\"d\", cmap=\"Greys\", xticklabels=labels, yticklabels=labels, annot_kws={\"size\": 16}, ax=axs[1])\n",
    "axs[1].tick_params(labelsize=18)\n",
    "axs[1].set_ylabel('True Label', fontsize=20, labelpad=15)\n",
    "axs[1].set_xlabel('Predicted Label', fontsize=20, labelpad=15)\n",
    "axs[1].set_title('Traditional transformer', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Move the model and inputs to the same device\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m inputs \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.71.220.60/home/tiendat/transformer-entropy-ids/notebooks/performace_test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Make sure the model is in evaluation mode\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix_2 = np.array([\n",
    "    [15102,0,0,1,8,5],\n",
    "    [7,2,0,0,0,0],\n",
    "    [66,0,2181,3,0,0],\n",
    "    [   46,0,1,1540,0,0],\n",
    "    [   20,0,0,0,1031,0],\n",
    "    [    3,0,0,0,0,987],\n",
    "])\n",
    "confusion_matrix = np.array([\n",
    "    [15102,0,0,1,8,0,0],\n",
    "    [0,9,0,0,0,0,0],\n",
    "    [0,0,12,0,0,0,0],\n",
    "    [0,0,0,2288,0,0,0],\n",
    "    [2,0,0,0,1689,0,0],\n",
    "    [0,0,0,0,0,1071,0],\n",
    "    [0,0,0,0,0,0,1006],\n",
    "])\n",
    "confusion_matrix_test = np.array([\n",
    "    [15094,1,0,0,11,5,0],\n",
    "    [0,9,0,0,0,0,0],\n",
    "    [0,0,12,0,0,0,0],\n",
    "    [7,0,0,2281,0,0,0],\n",
    "    [17,0,0,0,1673,1,0],\n",
    "    [0,0,0,0,0,1071,0],\n",
    "    [0,0,0,0,0,0,1006],\n",
    "])\n",
    "\n",
    "\n",
    "# List of attributes\n",
    "attributes = ['Normal', 'max_engine_coolant_temp_attack', 'fuzzing_attack', 'max_speedometer_attack', \n",
    "              'reverse_light_on_attack', 'reverse_light_off_attack', 'correlated_signal_attack']\n",
    "attributes2 = ['Normal', 'max_engine_coolant_temp_attack', 'max_speedometer_attack', \n",
    "              'reverse_light_on_attack', 'reverse_light_off_attack', 'correlated_signal_attack']\n",
    "\n",
    "# F1 score calculation for each attribute\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(len(attributes)):\n",
    "    TP = confusion_matrix[i, i]\n",
    "    TN = sum(sum(confusion_matrix)) - TP\n",
    "    FP = sum(confusion_matrix[:, i]) - TP\n",
    "    FN = sum(confusion_matrix[i, :]) - TP\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    FNR = (FN / (TP + FN))*100  # False Negative Rate\n",
    "    FPR = (FP / (FP + TN))*100  # False Positive Rate\n",
    "    print('Attribute: ', attributes[i])\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 score: ', f1_score)\n",
    "    print('False Negative Rate: ', FNR)  # Print FNR\n",
    "    print('False Positive Rate: ', FPR)  # Print FPR\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "f1_scores_per_attribute = dict(zip(attributes, f1_scores))\n",
    "f1_scores_per_attribute\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piptorchtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
