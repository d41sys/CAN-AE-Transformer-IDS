{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tiendat/transformer-entropy-ids/../', '/home/tiendat/transformer-entropy-ids/notebooks', '/home/tiendat/miniconda3/envs/torchtf/lib/python39.zip', '/home/tiendat/miniconda3/envs/torchtf/lib/python3.9', '/home/tiendat/miniconda3/envs/torchtf/lib/python3.9/lib-dynload', '', '/home/tiendat/miniconda3/envs/torchtf/lib/python3.9/site-packages', '../']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()) + \"/../\")\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 13:34:40.233248: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-13 13:34:40.285464: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 13:34:41.037747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tiendat/miniconda3/envs/torchtf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import vaex\n",
    "import numpy as np\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import _warnings\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import swifter\n",
    "import argparse\n",
    "import helper_functions\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(attack_dict):\n",
    "    df_aggregation = []\n",
    "    \n",
    "    for attack_name, metadata in attack_dict.items():    \n",
    "        if \"accelerator\" not in attack_name and \"metadata\" not in attack_name:\n",
    "            file_name = '/home/tiendat/transformer-entropy-ids/road/attacks/{}.log'.format(attack_name)\n",
    "            df_attack = helper_functions.make_can_df(file_name)\n",
    "            df_attack = helper_functions.add_time_diff_per_aid_col(df_attack)\n",
    "            df_aggregation.append(df_attack)\n",
    "            print(f\"Finish preprocess {file_name}\")\n",
    "    return df_aggregation\n",
    "\n",
    "def get_time_interval(attack_dict):\n",
    "    attack_metadata = []\n",
    "    \n",
    "    for attack_name, metadata in attack_dict.items():    \n",
    "        if \"accelerator\" not in attack_name and \"metadata\" not in attack_name:\n",
    "            print(f\"Finish get time interval of {attack_name}\")\n",
    "            attack_metadata.append([tuple(attack_dict[attack_name][\"injection_interval\"])])\n",
    "    return attack_metadata\n",
    "\n",
    "def mark_label(df_aggregation, attack_metadata, attack_dict):\n",
    "    count = 0\n",
    "    for attack_name, metadata in attack_dict.items():    \n",
    "        if \"accelerator\" not in attack_name and \"metadata\" not in attack_name:\n",
    "            print(f\"Index {count}: {attack_name} --- {attack_dict[attack_name]['injection_id']}\")\n",
    "            if attack_dict[attack_name][\"injection_id\"] != \"XXX\":\n",
    "                df_aggregation[count] = helper_functions.add_actual_attack_col(df_aggregation[count], attack_metadata[count], int(attack_dict[attack_name][\"injection_id\"], 16), attack_dict[attack_name][\"injection_data_str\"], attack_name)\n",
    "                print(len(df_aggregation[count][df_aggregation[count]['label'] == True]['label']))\n",
    "            else:\n",
    "                df_aggregation[count] = helper_functions.add_actual_attack_col(df_aggregation[count], attack_metadata[count], \"XXX\", attack_dict[attack_name][\"injection_data_str\"], attack_name)\n",
    "                print(len(df_aggregation[count][df_aggregation[count]['label'] == True]['label']))\n",
    "            count += 1\n",
    "    return df_aggregation\n",
    "\n",
    "def filter_attack(arr, keyword):\n",
    "    sub_array = []\n",
    "    for item in arr:\n",
    "        if keyword in item:\n",
    "            sub_array.append(item)\n",
    "    return sub_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/correlated_signal_attack_1.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/correlated_signal_attack_1_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/correlated_signal_attack_2.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/correlated_signal_attack_2_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/correlated_signal_attack_3.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/correlated_signal_attack_3_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/fuzzing_attack_1.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/fuzzing_attack_2.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/fuzzing_attack_3.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_engine_coolant_temp_attack.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_engine_coolant_temp_attack_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_speedometer_attack_1.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_speedometer_attack_1_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_speedometer_attack_2.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_speedometer_attack_2_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_speedometer_attack_3.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/max_speedometer_attack_3_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_off_attack_1.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_off_attack_1_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_off_attack_2.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_off_attack_2_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_off_attack_3.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_off_attack_3_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_on_attack_1.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_on_attack_1_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_on_attack_2.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_on_attack_2_masquerade.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_on_attack_3.log\n",
      "Finish preprocess /home/tiendat/transformer-entropy-ids/road/attacks/reverse_light_on_attack_3_masquerade.log\n",
      "Finish get time interval of correlated_signal_attack_1\n",
      "Finish get time interval of correlated_signal_attack_1_masquerade\n",
      "Finish get time interval of correlated_signal_attack_2\n",
      "Finish get time interval of correlated_signal_attack_2_masquerade\n",
      "Finish get time interval of correlated_signal_attack_3\n",
      "Finish get time interval of correlated_signal_attack_3_masquerade\n",
      "Finish get time interval of fuzzing_attack_1\n",
      "Finish get time interval of fuzzing_attack_2\n",
      "Finish get time interval of fuzzing_attack_3\n",
      "Finish get time interval of max_engine_coolant_temp_attack\n",
      "Finish get time interval of max_engine_coolant_temp_attack_masquerade\n",
      "Finish get time interval of max_speedometer_attack_1\n",
      "Finish get time interval of max_speedometer_attack_1_masquerade\n",
      "Finish get time interval of max_speedometer_attack_2\n",
      "Finish get time interval of max_speedometer_attack_2_masquerade\n",
      "Finish get time interval of max_speedometer_attack_3\n",
      "Finish get time interval of max_speedometer_attack_3_masquerade\n",
      "Finish get time interval of reverse_light_off_attack_1\n",
      "Finish get time interval of reverse_light_off_attack_1_masquerade\n",
      "Finish get time interval of reverse_light_off_attack_2\n",
      "Finish get time interval of reverse_light_off_attack_2_masquerade\n",
      "Finish get time interval of reverse_light_off_attack_3\n",
      "Finish get time interval of reverse_light_off_attack_3_masquerade\n",
      "Finish get time interval of reverse_light_on_attack_1\n",
      "Finish get time interval of reverse_light_on_attack_1_masquerade\n",
      "Finish get time interval of reverse_light_on_attack_2\n",
      "Finish get time interval of reverse_light_on_attack_2_masquerade\n",
      "Finish get time interval of reverse_light_on_attack_3\n",
      "Finish get time interval of reverse_light_on_attack_3_masquerade\n",
      "Index 0: correlated_signal_attack_1 --- 0x6e0\n",
      "2087\n",
      "Index 1: correlated_signal_attack_1_masquerade --- 0x6e0\n",
      "2087\n",
      "Index 2: correlated_signal_attack_2 --- 0x6e0\n",
      "2141\n",
      "Index 3: correlated_signal_attack_2_masquerade --- 0x6e0\n",
      "2141\n",
      "Index 4: correlated_signal_attack_3 --- 0x6e0\n",
      "1265\n",
      "Index 5: correlated_signal_attack_3_masquerade --- 0x6e0\n",
      "1265\n",
      "Index 6: fuzzing_attack_1 --- XXX\n",
      "36\n",
      "Index 7: fuzzing_attack_2 --- XXX\n",
      "16\n",
      "Index 8: fuzzing_attack_3 --- XXX\n",
      "4\n",
      "Index 9: max_engine_coolant_temp_attack --- 0x4e7\n",
      "43\n",
      "Index 10: max_engine_coolant_temp_attack_masquerade --- 0x4e7\n",
      "43\n",
      "Index 11: max_speedometer_attack_1 --- 0xd0\n",
      "2460\n",
      "Index 12: max_speedometer_attack_1_masquerade --- 0xd0\n",
      "2445\n",
      "Index 13: max_speedometer_attack_2 --- 0xd0\n",
      "3170\n",
      "Index 14: max_speedometer_attack_2_masquerade --- 0xd0\n",
      "3141\n",
      "Index 15: max_speedometer_attack_3 --- 0xd0\n",
      "6127\n",
      "Index 16: max_speedometer_attack_3_masquerade --- 0xd0\n",
      "6108\n",
      "Index 17: reverse_light_off_attack_1 --- 0xd0\n",
      "673\n",
      "Index 18: reverse_light_off_attack_1_masquerade --- 0xd0\n",
      "673\n",
      "Index 19: reverse_light_off_attack_2 --- 0xd0\n",
      "2378\n",
      "Index 20: reverse_light_off_attack_2_masquerade --- 0xd0\n",
      "2372\n",
      "Index 21: reverse_light_off_attack_3 --- 0xd0\n",
      "2435\n",
      "Index 22: reverse_light_off_attack_3_masquerade --- 0xd0\n",
      "2435\n",
      "Index 23: reverse_light_on_attack_1 --- 0xd0\n",
      "3269\n",
      "Index 24: reverse_light_on_attack_1_masquerade --- 0xd0\n",
      "1992\n",
      "Index 25: reverse_light_on_attack_2 --- 0xd0\n",
      "3754\n",
      "Index 26: reverse_light_on_attack_2_masquerade --- 0xd0\n",
      "3690\n",
      "Index 27: reverse_light_on_attack_3 --- 0xd0\n",
      "2292\n",
      "Index 28: reverse_light_on_attack_3_masquerade --- 0xd0\n",
      "2291\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/tiendat/transformer-entropy-ids/road/attacks/capture_metadata.json\", \"r\") as read_file:\n",
    "    attack_dict = json.load(read_file)\n",
    "\n",
    "# display(attack_dict)\n",
    "\n",
    "df_attack = get_all_data(attack_dict)\n",
    "attack_metadata = get_time_interval(attack_dict)\n",
    "df_attack = mark_label(df_attack, attack_metadata, attack_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambient_dyno_exercise_all_bits.log\n",
      "(4135914, 6)\n",
      "ambient_highway_street_driving_long.log\n",
      "(8264830, 6)\n",
      "ambient_dyno_drive_extended_short.log\n",
      "(741466, 6)\n",
      "ambient_dyno_drive_basic_short.log\n",
      "(996375, 6)\n",
      "ambient_dyno_drive_benign_anomaly.log\n",
      "(720822, 6)\n",
      "ambient_highway_street_driving_diagnostics.log\n",
      "(1053702, 6)\n",
      "ambient_dyno_idle_radio_infotainment.log\n",
      "(1472991, 6)\n",
      "ambient_dyno_reverse.log\n",
      "(115180, 6)\n",
      "ambient_dyno_drive_radio_infotainment.log\n",
      "(873911, 6)\n",
      "ambient_dyno_drive_extended_long.log\n",
      "(1334942, 6)\n",
      "ambient_dyno_drive_basic_long.log\n",
      "(2802326, 6)\n",
      "ambient_dyno_drive_winter.log\n",
      "(106832, 6)\n"
     ]
    }
   ],
   "source": [
    "df_normal = []\n",
    "\n",
    "for file_name in os.listdir(\"/home/tiendat/transformer-entropy-ids/road/ambient\"):\n",
    "    if \"metadata\" not in file_name:\n",
    "        print(file_name)\n",
    "        file_name = '/home/tiendat/transformer-entropy-ids/road/ambient/' + file_name\n",
    "        df = helper_functions.make_can_df(file_name)\n",
    "        df = helper_functions.add_time_diff_per_aid_col(df)\n",
    "        df['label'] = [False] * df.shape[0]\n",
    "        print(df.shape)\n",
    "        df_normal.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25677443, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attack_1 = pd.concat(df_attack)\n",
    "df_normal_1 = pd.concat(df_normal)\n",
    "\n",
    "df_all = []\n",
    "\n",
    "df_all.append(df_attack_1)\n",
    "df_all.append(df_normal_1)\n",
    "\n",
    "df_all = pd.concat(df_all)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25614610, 6), (62833, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_normal = df_all[df_all['label'] == False]\n",
    "df_all_attack = df_all[df_all['label'] == True]\n",
    "df_all_normal.shape, df_all_attack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22619291, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_normal_1 = pd.concat(df_normal)\n",
    "display(df_normal_1.shape)\n",
    "# 22619291\n",
    "display(df_normal_1[df_normal_1['label'] == True].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135914\n",
      "9\n",
      "8264830\n",
      "10\n",
      "741466\n",
      "1\n",
      "996375\n",
      "720822\n",
      "12\n",
      "1053702\n",
      "12\n",
      "1472991\n",
      "6\n",
      "115180\n",
      "10\n",
      "873911\n",
      "11\n",
      "1334942\n",
      "2\n",
      "2802326\n",
      "11\n",
      "106832\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the new DataFrames\n",
    "sub_dfs_normal = []\n",
    "sub_dfs_29 = []\n",
    "stride = 15\n",
    "\n",
    "for subd in df_normal:\n",
    "    # Loop through the original DataFrame in steps of 15 rows\n",
    "    subd = subd.sort_values(by=['time'], ascending=True)\n",
    "    print(len(subd))\n",
    "    for i in range(0, len(subd), stride):\n",
    "        if len(subd) - i < stride:\n",
    "            print(len(subd)-i)\n",
    "            sub_df = subd.iloc[i:len(subd)-1]\n",
    "        else:\n",
    "            sub_df = subd.iloc[i:i+stride]\n",
    "        sub_dfs_normal.append(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "max_sub_df = []\n",
    "min_sub_df = []\n",
    "\n",
    "def add_entropy_value(df, h_x, h_y, h_y_gv_x, mi, rule_entropy_dict):\n",
    "    aid = df['aid'].iloc[0]\n",
    "    if aid not in rule_entropy_dict:\n",
    "        if aid == 1760 or aid == 208:\n",
    "            print(\"=====================================\")\n",
    "            print(f\"Saw {aid} for the first time with mi = {mi}\")\n",
    "            print(f\"Entropy of X: {h_x}\")\n",
    "            print(f\"Entropy of Y: {h_y}\")\n",
    "            print(f\"Entropy of Y given X: {h_y_gv_x}\")\n",
    "            \n",
    "        rule_entropy_dict[aid] = { 'max_mi': mi, 'min_mi': mi, \n",
    "                                  'max_en_x': h_x, 'min_en_x': h_x, \n",
    "                                  'max_en_y': h_y, 'min_en_y': h_y, \n",
    "                                  'max_en_y_x': h_y_gv_x, 'min_en_y_x': h_y_gv_x}\n",
    "    else:\n",
    "        if (mi > rule_entropy_dict[aid]['max_mi'] \n",
    "            or mi < rule_entropy_dict[aid]['min_mi']\n",
    "            or h_x > rule_entropy_dict[aid]['max_en_x'] \n",
    "            or h_x < rule_entropy_dict[aid]['min_en_x']\n",
    "            or h_y > rule_entropy_dict[aid]['max_en_y'] \n",
    "            or h_y < rule_entropy_dict[aid]['min_en_y']\n",
    "            or h_y_gv_x > rule_entropy_dict[aid]['max_en_y_x']\n",
    "            or h_y_gv_x < rule_entropy_dict[aid]['min_en_y_x']) and (aid == 1760 or aid == 208):\n",
    "            print(\"=====================================\")\n",
    "            print(f\"Saw {aid} for the another time with mi = {mi}\")\n",
    "            print(f\"Entropy of X: {h_x}\")\n",
    "            print(f\"Entropy of Y: {h_y}\")\n",
    "            print(f\"Entropy of Y given X: {h_y_gv_x}\")\n",
    "            max_sub_df.append(df)\n",
    "        # Check mutual information\n",
    "        max_mi = max(rule_entropy_dict[aid]['max_mi'], mi)\n",
    "        min_mi = min(rule_entropy_dict[aid]['min_mi'], mi)\n",
    "        \n",
    "        # Check entropy of X\n",
    "        max_en_x = max(rule_entropy_dict[aid]['max_en_x'], h_x)\n",
    "        min_en_x = min(rule_entropy_dict[aid]['min_en_x'], h_x)\n",
    "        \n",
    "        # Check entropy of Y\n",
    "        max_en_y = max(rule_entropy_dict[aid]['max_en_y'], h_y)\n",
    "        min_en_y = min(rule_entropy_dict[aid]['min_en_y'], h_y)\n",
    "        \n",
    "        # Check entropy of Y given X\n",
    "        max_en_y_x = max(rule_entropy_dict[aid]['max_en_y_x'], h_y_gv_x)\n",
    "        min_en_y_x = min(rule_entropy_dict[aid]['min_en_y_x'], h_y_gv_x)\n",
    "        \n",
    "        rule_entropy_dict[aid]['max_en_x'] = max_en_x\n",
    "        rule_entropy_dict[aid]['min_en_x'] = min_en_x\n",
    "        \n",
    "        rule_entropy_dict[aid]['max_en_y'] = max_en_y\n",
    "        rule_entropy_dict[aid]['min_en_y'] = min_en_y\n",
    "        \n",
    "        rule_entropy_dict[aid]['max_en_y_x'] = max_en_y_x\n",
    "        rule_entropy_dict[aid]['min_en_y_x'] = min_en_y_x\n",
    "        \n",
    "        rule_entropy_dict[aid]['max_mi'] = max_mi\n",
    "        rule_entropy_dict[aid]['min_mi'] = min_mi\n",
    "        return rule_entropy_dict\n",
    "\n",
    "def create_threshold_dict(df, h_x, h_y, h_y_gv_x, mi, rule_entropy_dict, count):\n",
    "    if 'max_mi' not in rule_entropy_dict:\n",
    "        rule_entropy_dict = { 'max_mi': mi, 'min_mi': mi, \n",
    "                                  'max_en_x': h_x, 'min_en_x': h_x, \n",
    "                                  'max_en_y': h_y, 'min_en_y': h_y, \n",
    "                                  'max_en_y_x': h_y_gv_x, 'min_en_y_x': h_y_gv_x}\n",
    "        with open(\"/home/tiendat/transformer-entropy-ids/extract.txt\", \"a+\") as wrtie_file:\n",
    "            wrtie_file.write(f\"\\nFirst==========================================\\n\")\n",
    "            wrtie_file.write(f\"Mutual information: {mi}\\n\")\n",
    "            wrtie_file.write(f\"Entropy of X: {h_x}\\n\")\n",
    "            wrtie_file.write(f\"Entropy of Y: {h_y}\\n\")\n",
    "            wrtie_file.write(f\"Entropy of Y given X: {h_y_gv_x}\\n\")\n",
    "    else:\n",
    "        if (mi > rule_entropy_dict['max_mi'] \n",
    "            or mi < rule_entropy_dict['min_mi']\n",
    "            or h_x > rule_entropy_dict['max_en_x'] \n",
    "            or h_x < rule_entropy_dict['min_en_x']\n",
    "            or h_y > rule_entropy_dict['max_en_y'] \n",
    "            or h_y < rule_entropy_dict['min_en_y']\n",
    "            or h_y_gv_x > rule_entropy_dict['max_en_y_x']\n",
    "            or h_y_gv_x < rule_entropy_dict['min_en_y_x']):\n",
    "            max_sub_df.append(df)\n",
    "            with open(\"/home/tiendat/transformer-entropy-ids/extract.txt\", \"a+\") as wrtie_file:\n",
    "                wrtie_file.write(f\"\\nUpdated==========================================\\n\")\n",
    "                wrtie_file.write(f\"Mutual information: {mi}\\n\")\n",
    "                wrtie_file.write(f\"Entropy of X: {h_x}\\n\")\n",
    "                wrtie_file.write(f\"Entropy of Y: {h_y}\\n\")\n",
    "                wrtie_file.write(f\"Entropy of Y given X: {h_y_gv_x}\\n\")\n",
    "        if (mi == 0 or h_x == 0 or h_y == 0):\n",
    "            print(df)\n",
    "            \n",
    "        # Check mutual information\n",
    "        max_mi = max(rule_entropy_dict['max_mi'], mi)\n",
    "        min_mi = min(rule_entropy_dict['min_mi'], mi)\n",
    "        \n",
    "        # Check entropy of X\n",
    "        max_en_x = max(rule_entropy_dict['max_en_x'], h_x)\n",
    "        min_en_x = min(rule_entropy_dict['min_en_x'], h_x)\n",
    "        \n",
    "        # Check entropy of Y\n",
    "        max_en_y = max(rule_entropy_dict['max_en_y'], h_y)\n",
    "        min_en_y = min(rule_entropy_dict['min_en_y'], h_y)\n",
    "        \n",
    "        # Check entropy of Y given X\n",
    "        max_en_y_x = max(rule_entropy_dict['max_en_y_x'], h_y_gv_x)\n",
    "        min_en_y_x = min(rule_entropy_dict['min_en_y_x'], h_y_gv_x)\n",
    "        \n",
    "        rule_entropy_dict['max_en_x'] = max_en_x\n",
    "        rule_entropy_dict['min_en_x'] = min_en_x\n",
    "        \n",
    "        rule_entropy_dict['max_en_y'] = max_en_y\n",
    "        rule_entropy_dict['min_en_y'] = min_en_y\n",
    "        \n",
    "        rule_entropy_dict['max_en_y_x'] = max_en_y_x\n",
    "        rule_entropy_dict['min_en_y_x'] = min_en_y_x\n",
    "        \n",
    "        rule_entropy_dict['max_mi'] = max_mi\n",
    "        rule_entropy_dict['min_mi'] = min_mi\n",
    "        count += 1\n",
    "    return rule_entropy_dict, count\n",
    "\n",
    "def calculate_entropy_ver2(X):\n",
    "    p_x = defaultdict(float)\n",
    "    n = len(X)\n",
    "    \n",
    "    for x in X:\n",
    "        p_x[x] += 1 / n\n",
    "    \n",
    "    H_X = 0\n",
    "    for x in p_x:\n",
    "        H_X += -p_x[x] * np.log2(p_x[x])\n",
    "    return H_X\n",
    "\n",
    "def calculate_conditional_entropy_ver2(X, Y):\n",
    "    p_x = defaultdict(float)\n",
    "    p_y_given_x = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    n = len(X)\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        p_x[x] += 1 / n\n",
    "        p_y_given_x[x][y] += 1\n",
    "    \n",
    "    for x in p_y_given_x:\n",
    "        total = sum(p_y_given_x[x].values())\n",
    "        for y in p_y_given_x[x]:\n",
    "            p_y_given_x[x][y] /= total\n",
    "    \n",
    "    H_Y_given_X = 0\n",
    "    for x in p_x:\n",
    "        for y in p_y_given_x[x]:\n",
    "            H_Y_given_X += p_x[x] * p_y_given_x[x][y] * -np.log2(p_y_given_x[x][y])\n",
    "    return H_Y_given_X\n",
    "\n",
    "def calculate_mutual_information(df):\n",
    "    X = df['aid']\n",
    "    Y = df['data']\n",
    "    H_X = calculate_entropy_ver2(X)\n",
    "    H_Y = calculate_entropy_ver2(Y)\n",
    "    H_Y_given_X = calculate_conditional_entropy_ver2(X, Y)\n",
    "    I_X_Y = H_Y - H_Y_given_X\n",
    "    return H_X, H_Y, H_Y_given_X, I_X_Y\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# for subd in sub_dfs_normal:\n",
    "#     subd.groupby('aid').apply(calculate_mutual_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                time   aid              data      ori_time  time_diffs  label\n",
      "4419411  2172.794504  1505  893FE00802000080  1.050002e+09    0.010266  False\n",
      "4419412  2172.794505   354  00080003EA11F4C6  1.050002e+09    0.020010  False\n",
      "4419413  2172.794506   167  0090FA009105D0A0  1.050002e+09    0.010265  False\n",
      "4419414  2172.795509   208  0273046400000000  1.050002e+09    0.009189  False\n",
      "4419415  2172.795510    51  0007D8000C4007D0  1.050002e+09    0.009188  False\n",
      "4419416  2172.795511  1399  00000000000000AE  1.050002e+09    0.042105  False\n",
      "4419417  2172.796796    14  205356020808753A  1.050002e+09    0.009458  False\n",
      "4419418  2172.799462  1760  0000000000000000  1.050002e+09    0.007976  False\n",
      "                time   aid              data      ori_time  time_diffs  label\n",
      "8821903  3764.314535   208  7A740464ED0000D1  1.110004e+09    0.011753  False\n",
      "8821904  3764.314536    51  000768000FC007D0  1.110004e+09    0.010731  False\n",
      "8821905  3764.314537   628  00F20FED107C8EB9  1.110004e+09    0.019972  False\n",
      "8821906  3764.314538   870  7FDDC8020147CE78  1.110004e+09    0.018983  False\n",
      "8821907  3764.315520  1408  00000003F0880000  1.110004e+09    0.019964  False\n",
      "8821908  3764.315521  1076  030AA0A8D194B6B0  1.110004e+09    0.019963  False\n",
      "8821910  3764.315522   192  6000000000000000  1.110004e+09    0.018924  False\n",
      "8821909  3764.315522  1760  0000000000000000  1.110004e+09    0.013771  False\n",
      "8821911  3764.316567  1644  0080100020000020  1.110004e+09    0.099955  False\n",
      "Empty DataFrame\n",
      "Columns: [time, aid, data, ori_time, time_diffs, label]\n",
      "Index: []\n",
      "              time   aid              data      ori_time  time_diffs  label\n",
      "771504  456.445201  1176  84002000ED80000F  1.060000e+09    0.019058  False\n",
      "771505  456.445202   560  5A000CD27C001400  1.060000e+09    0.018031  False\n",
      "771506  456.447056   208  6A6C0464EF000000  1.060000e+09    0.008955  False\n",
      "771507  456.448108    51  000778000F4007D0  1.060000e+09    0.009011  False\n",
      "771509  456.450882    14  2053160208097568  1.060000e+09    0.009746  False\n",
      "771510  456.451891   852  1FFF40000003C580  1.060000e+09    0.009729  False\n",
      "771511  456.451892  1505  893FE00B0A000080  1.060000e+09    0.008713  False\n",
      "771512  456.451893   651  0000000000000000  1.060000e+09    0.019981  False\n",
      "771513  456.452899  1760  0000000000000000  1.060000e+09    0.008721  False\n",
      "771514  456.452901   167  2010FA24F12B30A0  1.060000e+09    0.007702  False\n",
      "771515  456.452902    61  0001F48000000000  1.060000e+09    0.099969  False\n",
      "               time   aid              data      ori_time  time_diffs  label\n",
      "1124735  469.933693   208  627D04604F00A100  1.070000e+09    0.011372  False\n",
      "1124736  469.934711    51  0004D0000F0567D0  1.070000e+09    0.012389  False\n",
      "1124737  469.934712   628  00F20CF0107C8E81  1.070000e+09    0.020985  False\n",
      "1124738  469.934713  1760  0099009900900096  1.070000e+09    0.009396  False\n",
      "1124739  469.934715   192  6000000000000000  1.070000e+09    0.019976  False\n",
      "1124740  469.935760   167  0010F824D12BF0A0  1.070000e+09    0.010444  False\n",
      "1124741  469.935762    61  0001300000000000  1.070000e+09    0.100002  False\n",
      "1124742  469.935763   263  0000000000000000  1.070000e+09    0.020016  False\n",
      "1124744  469.936765   186  068807C410000200  1.070000e+09    0.041016  False\n",
      "1124745  469.938271  1694  04400490202014E2  1.070000e+09    0.020065  False\n",
      "1124746  469.939235   293  90002B5F3CAB9960  1.070000e+09    0.010884  False\n",
      "               time   aid              data      ori_time  time_diffs  label\n",
      "1572310  660.778930  1031  4000DFF020806F20  1.050001e+09    0.099890  False\n",
      "1572311  660.779948  1399  0000080000000144  1.050001e+09    0.045886  False\n",
      "1572312  660.779949  1644  0080100018000020  1.050001e+09    0.099909  False\n",
      "1572313  660.782007   870  7FDDC8022147CCF8  1.050001e+09    0.019891  False\n",
      "1572314  660.783027  1408  00000003E9080000  1.050001e+09    0.020910  False\n",
      "             time   aid              data      ori_time  time_diffs  label\n",
      "123034  51.431109   339  00000004000C0004  1.080000e+09    0.020955  False\n",
      "123036  51.431111   661  0000000000000040  1.080000e+09    0.030798  False\n",
      "123037  51.431112  1634  4E20000040000000  1.080000e+09    0.019949  False\n",
      "123038  51.432138  1668  58DD8019416D501E  1.080000e+09    0.100946  False\n",
      "123039  51.432140  1590  249C0000F08B5000  1.080000e+09    0.099953  False\n",
      "123040  51.432141   727  100060D800000008  1.080000e+09    0.099953  False\n",
      "123041  51.432142   412  1CE2200002002880  1.080000e+09    0.020978  False\n",
      "123042  51.433124   208  72710460EE000000  1.080000e+09    0.012966  False\n",
      "123043  51.433125    51  000770000F8007D0  1.080000e+09    0.011964  False\n",
      "              time   aid              data      ori_time  time_diffs  label\n",
      "932838  390.437680   293  900040DF3EBFF560  1.100000e+09    0.009774  False\n",
      "932839  390.438699   692  188CF6000005D800  1.100000e+09    0.099991  False\n",
      "932840  390.444636  1760  0000000000000000  1.100000e+09    0.007957  False\n",
      "932841  390.446813    14  2052D60208087526  1.100000e+09    0.009135  False\n",
      "932842  390.447800   738  18080D4040000118  1.100000e+09    0.099969  False\n",
      "932843  390.447802   837  050202C23C774081  1.100000e+09    0.099970  False\n",
      "932844  390.447803   293  900040DF3EBFD760  1.100000e+09    0.010123  False\n",
      "932845  390.447804  1072  0000468BF28012A0  1.100000e+09    0.099970  False\n",
      "932846  390.448847   304  0001600000000000  1.100000e+09    0.099992  False\n",
      "932847  390.448848   263  0000000000000000  1.100000e+09    0.019943  False\n",
      "               time  aid              data      ori_time  time_diffs  label\n",
      "1424204  657.871228  167  0090FA006105E0A0  1.090001e+09    0.009804  False\n",
      "                time   aid              data      ori_time  time_diffs  label\n",
      "2991259  1250.941452   661  0000000000000040  1.110001e+09    0.030966  False\n",
      "2991260  1250.941454  1634  4F60000040000000  1.110001e+09    0.019803  False\n",
      "2991261  1250.941455   412  10EE200002002970  1.110001e+09    0.019803  False\n",
      "2991262  1250.941456   208  427B0460F4000000  1.110001e+09    0.010972  False\n",
      "2991263  1250.942505   737  0000000000000004  1.110001e+09    0.019858  False\n",
      "2991264  1250.942506   852  1FFF400000041800  1.110001e+09    0.009980  False\n",
      "2991265  1250.942507  1505  893FE00B0A000080  1.110001e+09    0.009980  False\n",
      "2991266  1250.942508  1413  0040000000020018  1.110001e+09    0.098000  False\n",
      "2991267  1250.943525    51  0007A0000E0007D0  1.110001e+09    0.012020  False\n",
      "2991268  1250.943526   628  00F208F7107C81DD  1.110001e+09    0.020876  False\n",
      "             time  aid              data      ori_time  time_diffs  label\n",
      "114144  47.729504  737  0000000000000004  1.050000e+09    0.020001  False\n",
      "{'max_mi': 3.906890595608518, 'min_mi': 1.7464657985040721, 'max_en_x': 3.906890595608518, 'min_en_x': 1.7464657985040721, 'max_en_y': 3.906890595608518, 'min_en_y': 1.9628066316931743, 'max_en_y_x': 0.7999999999999999, 'min_en_y_x': 0.0} 1507946\n"
     ]
    }
   ],
   "source": [
    "rule_entropy_dict = {}\n",
    "count = 0\n",
    "\n",
    "for subd in sub_dfs_normal:\n",
    "    if len(subd) < 15:\n",
    "        print(subd)\n",
    "        continue\n",
    "    H_X, H_Y, H_Y_given_X, I_X_Y = calculate_mutual_information(subd)\n",
    "    rule_entropy_dict, count = create_threshold_dict(subd, H_X, H_Y, H_Y_given_X, I_X_Y, rule_entropy_dict, count)\n",
    "    # subd.groupby('aid').apply(calculate_mutual_information)\n",
    "print(rule_entropy_dict, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[263, 186, 263, 813, 263, 186, 263, 263, 186, 1307, 813, 60, 519, 1225, 470]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sub_df[6]['aid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7464657985040721"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.9628066316931743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2163408331891021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.7464657985040721"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X = [6, 6, 37, 208, ]\n",
    "# Y = ['0273046400000000', '0000000000000000', '0000000000000000', '3A770C60F5000000']\n",
    "X = [263, 186, 263, 813, 263, 186, 263, 813, 263, 186, 263, 263, 186, 813, 60]\n",
    "Y = ['0000000000000000',\n",
    " '04A7F484000606A0',\n",
    " '0000000000000000',\n",
    " '8000042758010000',\n",
    " '0000000000000000',\n",
    " '04A7F4C4000606A0',\n",
    " '0000000000000000',\n",
    " '8000042758010000',\n",
    " '0000000000000000',\n",
    " '04A7F4C4000606A0',\n",
    " '0000000000000000',\n",
    " '0000000000000000',\n",
    " '04A7F4C4000606A0',\n",
    " '8000042758010000',\n",
    " '000004002E000000']\n",
    "# X = ['0E','4A','0E','4B']\n",
    "# Y = ['0E','5A','0E','53']\n",
    "H_X = calculate_entropy_ver2(X)\n",
    "H_Y = calculate_entropy_ver2(Y)\n",
    "H_Y_given_X = calculate_conditional_entropy_ver2(X, Y)\n",
    "\n",
    "I_X_Y = H_Y - H_Y_given_X\n",
    "\n",
    "display(H_X)\n",
    "display(H_Y)\n",
    "display(H_Y_given_X)\n",
    "display(I_X_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([                time  aid              data      ori_time  time_diffs  label\n",
       "  4419414  2172.795509  208  0273046400000000  1.050002e+09    0.009189  False\n",
       "  4419391  2172.786320  208  0273046400000000  1.050002e+09    0.010825  False,\n",
       "                  time   aid              data      ori_time  time_diffs  label\n",
       "  4419418  2172.799462  1760  0000000000000000  1.050002e+09    0.007976  False\n",
       "  4419405  2172.791486  1760  0000000000000000  1.050002e+09    0.011934  False,\n",
       "                  time  aid              data      ori_time  time_diffs  label\n",
       "  4414323  2169.946025  208  0A730464FB000000  1.050002e+09    0.008013  False\n",
       "  4414306  2169.938012  208  02730464FC000000  1.050002e+09    0.012007  False,\n",
       "                  time   aid              data      ori_time  time_diffs  label\n",
       "  3847531  1932.872471  1760  0054005A00580053  1.050002e+09    0.008245  False\n",
       "  3847513  1932.864226  1760  005A005F005E0057  1.050002e+09    0.012263  False,\n",
       "                  time  aid              data      ori_time  time_diffs  label\n",
       "  1926308  1129.382601  208  4A770C60F3000000  1.050001e+09    0.007976  False\n",
       "  1926303  1129.374625  208  42770C60F4000000  1.050001e+09    0.012021  False\n",
       "  1926290  1129.362604  208  3A770C60F5000000  1.050001e+09    0.018998  False,\n",
       "                  time  aid              data      ori_time  time_diffs  label\n",
       "  8405543  3565.531244  208  52770460850B62D1  1.110004e+09    0.020986  False\n",
       "  8405532  3565.510258  208  42770460860B63D1  1.110004e+09    0.039027  False\n",
       "  8405528  3565.471231  208  227704607F0B6ED1  1.110004e+09    0.010222  False\n",
       "  8405523  3565.461009  208  1A770460800B6ED1  1.110004e+09    0.010755  False,\n",
       "                  time   aid              data      ori_time  time_diffs  label\n",
       "  8397319  3559.526133  1760  0E4A0E4B0E5A0E53  1.110004e+09    0.039837  False\n",
       "  8397305  3559.486296  1760  0E460E4B0E610E5C  1.110004e+09    0.039901  False\n",
       "  8397289  3559.446395  1760  0E490E4D0E4B0E5B  1.110004e+09    0.008015  False],\n",
       " [0.0, 0.0, 1.0, 1.0, 1.584962500721156, 2.0, 1.584962500721156])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sub_df, mi_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_payload(payload):\n",
    "    \"\"\"Convert a payload into a list of 8 elements, each of 2 bytes.\"\"\"\n",
    "    return [[payload[i:i+2]] for i in range(0, len(payload), 2)]\n",
    "\n",
    "def update_pattern_list(pattern_list, new_payload):\n",
    "    \"\"\"Update the pattern list with new 2-byte values from a new payload.\"\"\"\n",
    "    new_values = process_payload(new_payload)\n",
    "    for i in range(8):\n",
    "        # If the value is not already in the list for that index, append it\n",
    "        if new_values[i][0] not in pattern_list[i]:\n",
    "            pattern_list[i].append(new_values[i][0])\n",
    "\n",
    "def get_patterns_from_df(df, pattern_dict):\n",
    "    \"\"\"Get a list of patterns from a DataFrame.\"\"\"\n",
    "    aid = df['aid'].iloc[0]\n",
    "    pattern_list = [[] for _ in range(8)]\n",
    "    \n",
    "    start = time.time()\n",
    "    for payload in df['data']:\n",
    "        update_pattern_list(pattern_list, payload)\n",
    "    \n",
    "    print(f\"Time taken: {time.time() - start} seconds for aid {aid}\")\n",
    "    pattern_dict[str(aid)] = pattern_list\n",
    "    return pattern_list\n",
    "\n",
    "def check_single_payload_matching(payload, pattern_list):\n",
    "    \"\"\"Check if a single payload matches a pattern list.\"\"\"\n",
    "    new_values = process_payload(payload)\n",
    "    for i in range(8):\n",
    "        if new_values[i][0] not in pattern_list[i]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_payload_matching(df, pattern_dict):\n",
    "    \"\"\"Check if a payload matches a pattern list.\"\"\"\n",
    "    aid = df['aid'].iloc[0]\n",
    "    detected_label = df['data'].apply(lambda x: check_single_payload_matching(x, pattern_dict[str(aid)]))\n",
    "    return detected_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.025541305541992188 seconds for aid 6\n",
      "Time taken: 3.807551860809326 seconds for aid 14\n",
      "Time taken: 0.04278993606567383 seconds for aid 37\n",
      "Time taken: 6.030519485473633 seconds for aid 51\n",
      "Time taken: 0.05768275260925293 seconds for aid 58\n",
      "Time taken: 0.28849220275878906 seconds for aid 60\n",
      "Time taken: 0.4703357219696045 seconds for aid 61\n",
      "Time taken: 0.026808738708496094 seconds for aid 65\n",
      "Time taken: 0.10098838806152344 seconds for aid 117\n",
      "Time taken: 3.4111287593841553 seconds for aid 167\n",
      "Time taken: 1.2008259296417236 seconds for aid 186\n",
      "Time taken: 1.234982967376709 seconds for aid 192\n",
      "Time taken: 0.040313005447387695 seconds for aid 204\n",
      "Time taken: 6.66971755027771 seconds for aid 208\n",
      "Time taken: 0.25423622131347656 seconds for aid 215\n",
      "Time taken: 0.0690009593963623 seconds for aid 241\n",
      "Time taken: 0.24387860298156738 seconds for aid 244\n",
      "Time taken: 0.02564072608947754 seconds for aid 248\n",
      "Time taken: 0.026124954223632812 seconds for aid 253\n",
      "Time taken: 1.3011114597320557 seconds for aid 263\n",
      "Time taken: 4.880526304244995 seconds for aid 293\n",
      "Time taken: 0.04095315933227539 seconds for aid 300\n",
      "Time taken: 0.25611448287963867 seconds for aid 304\n",
      "Time taken: 1.2560417652130127 seconds for aid 339\n",
      "Time taken: 1.763166904449463 seconds for aid 354\n",
      "Time taken: 1.469944953918457 seconds for aid 403\n",
      "Time taken: 2.84190034866333 seconds for aid 412\n",
      "Time taken: 0.029531002044677734 seconds for aid 420\n",
      "Time taken: 0.026573657989501953 seconds for aid 426\n",
      "Time taken: 0.10641932487487793 seconds for aid 452\n",
      "Time taken: 0.27848362922668457 seconds for aid 458\n",
      "Time taken: 0.30147862434387207 seconds for aid 470\n",
      "Time taken: 0.025585174560546875 seconds for aid 485\n",
      "Time taken: 0.32707953453063965 seconds for aid 519\n",
      "Time taken: 2.3682942390441895 seconds for aid 526\n",
      "Time taken: 0.02781057357788086 seconds for aid 541\n",
      "Time taken: 1.8203370571136475 seconds for aid 560\n",
      "Time taken: 0.42650628089904785 seconds for aid 569\n",
      "Time taken: 0.3119642734527588 seconds for aid 622\n",
      "Time taken: 0.026591777801513672 seconds for aid 627\n",
      "Time taken: 2.0245742797851562 seconds for aid 628\n",
      "Time taken: 0.020011186599731445 seconds for aid 631\n",
      "Time taken: 0.12390351295471191 seconds for aid 640\n",
      "Time taken: 1.2465243339538574 seconds for aid 651\n",
      "Time taken: 0.8246495723724365 seconds for aid 661\n",
      "Time taken: 0.06250977516174316 seconds for aid 663\n",
      "Time taken: 0.3940112590789795 seconds for aid 675\n",
      "Time taken: 0.1071157455444336 seconds for aid 676\n",
      "Time taken: 0.060302019119262695 seconds for aid 683\n",
      "Time taken: 0.5787642002105713 seconds for aid 692\n",
      "Time taken: 0.025422096252441406 seconds for aid 695\n",
      "Time taken: 0.5629026889801025 seconds for aid 705\n",
      "Time taken: 0.3161447048187256 seconds for aid 722\n",
      "Time taken: 0.24556255340576172 seconds for aid 727\n",
      "Time taken: 1.2438023090362549 seconds for aid 737\n",
      "Time taken: 0.2589139938354492 seconds for aid 738\n",
      "Time taken: 0.08920812606811523 seconds for aid 778\n",
      "Time taken: 0.5647463798522949 seconds for aid 813\n",
      "Time taken: 0.24488377571105957 seconds for aid 837\n",
      "Time taken: 5.7338175773620605 seconds for aid 852\n",
      "Time taken: 1.3444230556488037 seconds for aid 870\n",
      "Time taken: 0.02626967430114746 seconds for aid 881\n",
      "Time taken: 0.0197906494140625 seconds for aid 930\n",
      "Time taken: 0.054018259048461914 seconds for aid 953\n",
      "Time taken: 2.58855938911438 seconds for aid 961\n",
      "Time taken: 0.27764105796813965 seconds for aid 996\n",
      "Time taken: 0.621713399887085 seconds for aid 1031\n",
      "Time taken: 0.053389549255371094 seconds for aid 1049\n",
      "Time taken: 0.5040972232818604 seconds for aid 1072\n",
      "Time taken: 4.893863677978516 seconds for aid 1076\n",
      "Time taken: 0.2986593246459961 seconds for aid 1124\n",
      "Time taken: 0.25167417526245117 seconds for aid 1175\n",
      "Time taken: 3.691683292388916 seconds for aid 1176\n",
      "Time taken: 0.29336977005004883 seconds for aid 1225\n",
      "Time taken: 0.1204838752746582 seconds for aid 1227\n",
      "Time taken: 0.31090879440307617 seconds for aid 1255\n",
      "Time taken: 0.03291034698486328 seconds for aid 1262\n",
      "Time taken: 0.8529584407806396 seconds for aid 1277\n",
      "Time taken: 0.1678168773651123 seconds for aid 1307\n",
      "Time taken: 2.033348321914673 seconds for aid 1314\n",
      "Time taken: 0.050524234771728516 seconds for aid 1331\n",
      "Time taken: 0.2138817310333252 seconds for aid 1372\n",
      "Time taken: 0.026211977005004883 seconds for aid 1398\n",
      "Time taken: 0.5701127052307129 seconds for aid 1399\n",
      "Time taken: 2.4899208545684814 seconds for aid 1408\n",
      "Time taken: 0.25997018814086914 seconds for aid 1413\n",
      "Time taken: 0.030472755432128906 seconds for aid 1455\n",
      "Time taken: 0.2646644115447998 seconds for aid 1459\n",
      "Time taken: 3.2230923175811768 seconds for aid 1505\n",
      "Time taken: 0.02750396728515625 seconds for aid 1512\n",
      "Time taken: 0.02821826934814453 seconds for aid 1533\n",
      "Time taken: 0.024176836013793945 seconds for aid 1560\n",
      "Time taken: 0.45821261405944824 seconds for aid 1590\n",
      "Time taken: 0.038481712341308594 seconds for aid 1621\n",
      "Time taken: 0.5191855430603027 seconds for aid 1628\n",
      "Time taken: 1.2587096691131592 seconds for aid 1634\n",
      "Time taken: 0.2550661563873291 seconds for aid 1644\n",
      "Time taken: 0.0037310123443603516 seconds for aid 1649\n",
      "Time taken: 0.033640384674072266 seconds for aid 1661\n",
      "Time taken: 0.38313722610473633 seconds for aid 1668\n",
      "Time taken: 0.030289888381958008 seconds for aid 1693\n",
      "Time taken: 1.4003381729125977 seconds for aid 1694\n",
      "Time taken: 0.04201340675354004 seconds for aid 1751\n",
      "Time taken: 11.01211404800415 seconds for aid 1760\n",
      "Time taken: 0.46158528327941895 seconds for aid 1788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "aid\n",
       "6       [[08, 00], [00], [00], [64, 00], [00], [00], [...\n",
       "14      [[20], [52, 53, 51, 54, 55, 56, 50, 67, 4F, 4E...\n",
       "37      [[00], [00], [02, 0A, 0B, 0C, 0D, 0E, 0F, 10, ...\n",
       "51      [[00, 08, 09, 0B, 0D, 0E, 0F, 10, 11, 12, 13, ...\n",
       "58      [[00], [00], [00], [00], [00], [1D, 1A, 17, 16...\n",
       "60      [[00], [00], [04, 00], [00], [2E, 2F, 2D, 2B, ...\n",
       "61      [[00, 07, 04, 03, 02, 01, 05, 06], [00, 01, D0...\n",
       "65      [[80, 81], [22, A2, 42], [00], [20], [01, 00],...\n",
       "117     [[0F, 0E, 00, 0D, 0C, 0B, 08, 09, 0A], [32, 8E...\n",
       "167     [[00, 10, 20, 30], [10, 11, 70, 71, 51, 50, 90...\n",
       "186     [[06, 05, 04, 03], [B8, A8, 98, C8, 67, 17, C7...\n",
       "192     [[60, 20, 00, 40, A0], [00], [00, 10], [00], [...\n",
       "204     [[43], [41, 40, 31, 39, 38], [04, 05, 06, 07, ...\n",
       "208     [[52, 5A, 62, 6A, 72, 7A, 02, 0A, 12, 1A, 22, ...\n",
       "215     [[00], [00, 01, 03, 02], [02, 01, 1A, 52, 6A, ...\n",
       "241     [[3E, 64, 42, 3B, 3A, 3C, 3D, 43, 44, 48, 4A, ...\n",
       "244     [[9A, 9F, 95, 96, 99], [0C], [01], [02], [04, ...\n",
       "248     [[7E, 3E], [DF, 1B], [F4], [FD, FC], [49, 41],...\n",
       "253     [[00], [00], [01], [00], [80, 00], [10, 00], [...\n",
       "263     [[00, 02], [00, 02, 0E, 03], [00, 6D, 20, BA, ...\n",
       "293     [[90], [00, 80], [41, 40, 3F, 2D, 2E, FF, 3E, ...\n",
       "300     [[79, 71, 29, 21, 25, 19, 1D, 2D, 31, 35, 3D, ...\n",
       "304     [[00, 10], [01, 00, 03, 05, 04, 06, 07], [60, ...\n",
       "339     [[00, 40, 04, 08], [00, 01], [00], [00, 04], [...\n",
       "354     [[00, 24, 2E, 2F, 2D, 2C, FF, 01, 25, 26, 27, ...\n",
       "403     [[00], [08], [08], [03, 04, 02, 05, 0B], [E7, ...\n",
       "412     [[18, 1C, 00, 04, 08, 0C, 10, 14, 0D, 11, 15, ...\n",
       "420     [[00], [00], [00], [02, 01, 00], [EC, E4, AC, ...\n",
       "426     [[90], [BE, 2E, 3E], [BD, A1, B5], [44], [A1, ...\n",
       "452     [[00, 01], [00, 02, 72, 70], [02], [00], [00, ...\n",
       "458     [[3F, 00], [F1, F9, 00], [FF, 00], [80, 00], [...\n",
       "470     [[02, 06, 0E, 0A], [0B, 0F, 8B, 8F, 0D, 09, 8D...\n",
       "485     [[01], [46], [04], [05], [A8, E6], [41], [A3, ...\n",
       "519     [[04, 24], [04, 00], [60, E0, 20, A0, 40, C0, ...\n",
       "526     [[4E], [20, 1F, 3F, 21, 22, 23, 24, 25, 26, 27...\n",
       "541     [[00], [00, 02, 04, 06, 08, 0A, 0C, 0E, 1A, 20...\n",
       "560     [[F2, F1, F0, FF, FE, FD, FC, FB, FA, F9, F8, ...\n",
       "569     [[00], [00, 01], [00], [76, 77, 75, 74, 73, 72...\n",
       "622     [[01, 0D, 05], [06, 0A, 09, 0C, 0D, 0E, 0B, 0F...\n",
       "627     [[00, 08, 18], [00, 40], [00], [08, 09], [00],...\n",
       "628     [[00, 28, 68, 51, 58, 40, 08, 48, 18, 50, 11, ...\n",
       "631     [[1E, 10, 18, 1D, 20, 01, 04], [01, 03, 0D, 0C...\n",
       "640     [[18, 10, 00, 58, 78, 1C, 38], [E0, 00, 02, 80...\n",
       "651     [[00, 10], [00], [00], [00], [00, 01], [00, C0...\n",
       "661     [[00], [00], [00], [00], [00], [00], [18, 08, ...\n",
       "663     [[11, 31, 00, 20, 10, 19, 01], [00, 02, 01, 50...\n",
       "675     [[00, 10, 01], [00, 02, 03, 04, 05, 06, 07, 01...\n",
       "676     [[36, 4E, 2E, 20], [DC, 1E, 8C, 20], [00, 01, ...\n",
       "683     [[A4, B0, B4], [D0, C0], [C9, D1, D9, C3, CB, ...\n",
       "692     [[14, 04, 12, 00, 01, 02, 03, 05, 06, 07, 08, ...\n",
       "695     [[00], [20], [28], [40, 42], [00, 20, 40, 60],...\n",
       "705     [[01, 04, 02], [F2, F3, F4, F1, F5, F6, 00, F7...\n",
       "722     [[00, 80], [00, 28, 2D, 2B, 2A, 2C, 29, 24, 27...\n",
       "727     [[10], [00], [60, 47, 48, 49, 4A, 4B, 4C, 4D, ...\n",
       "737     [[00], [00], [00, 8B, 8A, 80, 82, 88, 8E, 81, ...\n",
       "738     [[18, 78, 00], [08, 00], [0D, 3C, 0C, 0E, 00],...\n",
       "778     [[40, 20, C0, A0, E0], [2D, 22, 2C, 27, 28, 29...\n",
       "813     [[00, 80, C0, 40], [00, 01], [04, D4, 94, B4, ...\n",
       "837     [[05, 01], [02], [02], [C2, E5, C1], [3C, A0, ...\n",
       "852     [[20, 1F, 00, 21], [0A, 0B, 0C, 0D, 0E, 0F, 10...\n",
       "870     [[81, 80, 7F, 7E, 7D, 7C, 82, 83, 7B, 7A, 79, ...\n",
       "881     [[01, 00, 0A, 14, 1E, 3C, 5A, 78, B4, 02], [06...\n",
       "930     [[00, 8E, 9C, 9A, 20, 22, 24, A0, A2, 0A, 94, ...\n",
       "953     [[20], [04], [72, 32, 52], [00, 01, 08, 07, 06...\n",
       "961     [[7B], [55, 95, 15], [1F, 7F, 3F, 20, 21, 22, ...\n",
       "996     [[00, 01], [D4, D8, CC, D0, 34, 1C, 28, 24, 20...\n",
       "1031    [[50, D0, 40, 48, 08, 28, 39, 29, B9, B0, 90, ...\n",
       "1049    [[0A, 02], [9B, 1B], [46, C6], [4D, CD], [04],...\n",
       "1072    [[00, 02, 0A, 0C, 10, 14, 18, 1A, 1E, 22, 24, ...\n",
       "1076    [[03, 04, 00, 01, 02], [80, A2, CA, E2, 0A, 22...\n",
       "1124    [[00], [02], [40], [00, 40, 80, 02, C0], [00, ...\n",
       "1175    [[00], [00], [00, 40], [00], [00, 10], [00], [...\n",
       "1176    [[87, 84, 83, 85, 82, 81, 86, 80], [FF, 00, 01...\n",
       "1225    [[01], [F9, F8, 99, 98, C1, C0, B9, BF, BE, BC...\n",
       "1227    [[80], [00, 20], [00], [00], [00], [00, 0E, 02...\n",
       "1255    [[00], [00], [00], [14, 13, 15, 16, 17, 12, 11...\n",
       "1262    [[A0, A8], [00, C0, 82, C2, 80, 02, 42, 40], [...\n",
       "1277    [[11, 00, 01], [44, 40, 4C, 45, 43, 47, 4A, 46...\n",
       "1307    [[29, 28, 08], [09, 0C, 02, 1A, 42, B1, 01], [...\n",
       "1314    [[DF], [7F], [D0, D1, DF], [00, AC, A8, A4, A1...\n",
       "1331    [[ED], [7F], [CF], [7E], [FF], [F3, F4, F5, F6...\n",
       "1372    [[10, 00, 04, 08, 11], [1B, 1C, 00, 1D, 1A, 19...\n",
       "1398    [[7F, 00], [F8, 00], [00], [00, 20], [3F, 00],...\n",
       "1399    [[00], [00], [08, 00], [00], [00], [00], [01, ...\n",
       "1408    [[00], [00], [00], [03, 04, 05, 06, 07, 00, 01...\n",
       "1413    [[00, 02, 04, 08], [40], [00, 40, 80], [00, 20...\n",
       "1455    [[20, 30], [C0, 80, 00, 40, 04, 01, 02, 72, 7A...\n",
       "1459    [[04], [00, 40, 80], [00, 10], [00], [00], [00...\n",
       "1505    [[89], [3F, 3E, 3D, 3C, 3B, 3A, 39, 38, 37, 36...\n",
       "1512    [[00, 3E, 25, 37, 19, 39, 34, 3B, 35, 32, 31, ...\n",
       "1533    [[BD], [DD], [FD], [FF, F1, 80], [FE, 7E], [FF...\n",
       "1560    [[FB], [7D, 75], [BE, 86], [FF], [F7, F1, D7],...\n",
       "1590    [[24], [9C, A4, 88, 76, 92], [00, 01, 02, 03, ...\n",
       "1621    [[88, 8C, 90, 94, 98, 9C, A0, A4, A8, AC, B0, ...\n",
       "1628    [[40, 41, 42, 43], [08, 09, 11, 0E, 0F, 0D, 10...\n",
       "1634    [[4E, 4F, 4C, 4D, 4B, 4A, 49, 3C, 50, 51, 52, ...\n",
       "1644    [[00, 01], [00, 80, 40, 5B, 5C, 1C, 1B, 1A], [...\n",
       "1649    [[E7], [BF, 87], [FB], [D5], [DB], [DD], [BF],...\n",
       "1661    [[00], [18, 0A, 17, 00, 1A], [60, C0, 80, A0, ...\n",
       "1668    [[4C, 54, 28, 58, 50, 5C, 64, 68, 6C, 70, 74, ...\n",
       "1693    [[80, 64, E4], [8D, 9A, 5F, 9F, 1F, DF, 5A, 1A...\n",
       "1694    [[04, 80], [40], [04, 00, 06, 02], [7D, 7C, 7E...\n",
       "1751    [[41, 40, 01, 00], [04, 01, 02, 03, 09, 0B, 06...\n",
       "1760    [[01, 02, 03, 00, 08, 07, 06, 05, 04, 09, 0A, ...\n",
       "1788    [[00, 80], [00], [07, 06, 17, 47, 08, 09, 46, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_dict = {}\n",
    "df_all_normal.groupby('aid').apply(get_patterns_from_df, pattern_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pattern_dict[\u001b[39m6\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mmaxtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m12\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "pattern_dict[6]['maxtime'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_label = df_all_attack.groupby('aid').apply(check_payload_matching, pattern_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data\n",
       "True     34516\n",
       "False    28317\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = detected_label.value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/tiendat/transformer-entropy-ids/pattern_dict.json', 'w+') as fp:\n",
    "    json.dump(pattern_dict, fp)\n",
    "    \n",
    "for key, value in pattern_dict.items():\n",
    "    for i in range(len(value)):\n",
    "        print(f\"Length of pattern list for aid {key} at index {i}: {len(value[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ATTACK DATAFRAMEs\n",
    "sub_dfs_attack = []\n",
    "stride = 15\n",
    "\n",
    "for subd in df_attack:\n",
    "    # Loop through the original DataFrame in steps of 15 rows\n",
    "    subd = subd.sort_values(by=['time'], ascending=False)\n",
    "    print(len(subd))\n",
    "    for i in range(0, len(subd), stride):\n",
    "        if len(subd) - i < stride:\n",
    "            print(len(subd)-i)\n",
    "            sub_df = subd.iloc[i:len(subd)-1]\n",
    "        else:\n",
    "            sub_df = subd.iloc[i:i+stride]\n",
    "        sub_dfs_attack.append(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3058125\n",
      "Attack real: 59821\n",
      "Attack predict: 0\n",
      "Accuracy: 0.0\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[253], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRecall: \u001b[39m\u001b[39m{\u001b[39;00mattack_predict\u001b[39m/\u001b[39mattack_real\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrecision: \u001b[39m\u001b[39m{\u001b[39;00mattack_predict\u001b[39m/\u001b[39m(attack_predict\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m(total\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mattack_real))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF1 score: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m2\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m \u001b[39;49m(attack_predict\u001b[39m/\u001b[39;49m(attack_predict\u001b[39m \u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m \u001b[39;49m(total\u001b[39m \u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m \u001b[39;49mattack_real)))\u001b[39m \u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m \u001b[39;49m(attack_predict\u001b[39m/\u001b[39;49mattack_real)\u001b[39m \u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m \u001b[39;49m((attack_predict\u001b[39m/\u001b[39;49m(attack_predict\u001b[39m \u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m \u001b[39;49m(total\u001b[39m \u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m \u001b[39;49mattack_real)))\u001b[39m \u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m \u001b[39;49m(attack_predict\u001b[39m/\u001b[39;49mattack_real))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m display(subd_attacked, mi_attacked)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def calculate_entropy_ver2(X):\n",
    "    p_x = defaultdict(float)\n",
    "    n = len(X)\n",
    "    \n",
    "    for x in X:\n",
    "        p_x[x] += 1 / n\n",
    "    \n",
    "    H_X = 0\n",
    "    for x in p_x:\n",
    "        H_X += -p_x[x] * np.log2(p_x[x])\n",
    "    return H_X\n",
    "\n",
    "def calculate_conditional_entropy_ver2(X, Y):\n",
    "    p_x = defaultdict(float)\n",
    "    p_y_given_x = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    n = len(X)\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        p_x[x] += 1 / n\n",
    "        p_y_given_x[x][y] += 1\n",
    "    \n",
    "    for x in p_y_given_x:\n",
    "        total = sum(p_y_given_x[x].values())\n",
    "        for y in p_y_given_x[x]:\n",
    "            p_y_given_x[x][y] /= total\n",
    "    \n",
    "    H_Y_given_X = 0\n",
    "    for x in p_x:\n",
    "        for y in p_y_given_x[x]:\n",
    "            H_Y_given_X += p_x[x] * p_y_given_x[x][y] * -np.log2(p_y_given_x[x][y])\n",
    "    \n",
    "    return H_Y_given_X\n",
    "\n",
    "def check_mutual_information(df, rule_mi_dict):\n",
    "    X = df['aid']\n",
    "    Y = df['data']\n",
    "    H_X = calculate_entropy(X)\n",
    "    H_Y = calculate_entropy(Y)\n",
    "    H_Y_given_X = calculate_conditional_entropy(X, Y)\n",
    "    \n",
    "    I_X_Y = H_Y - H_Y_given_X\n",
    "    # if I_X_Y > rule_mi_dict[X.iloc[0]]['max_mi']:\n",
    "    #     return True\n",
    "    return I_X_Y\n",
    "    # return I_X_Y\n",
    "\n",
    "total = 0\n",
    "attack_real = 0\n",
    "attack_predict = 0\n",
    "subd_attacked = []\n",
    "mi_attacked = []\n",
    "\n",
    "for subd in sub_dfs:\n",
    "    start = time.time()\n",
    "    total += len(subd)    \n",
    "    predict_result = subd.groupby('aid').apply(check_mutual_information, rule_mi_dict)\n",
    "    \n",
    "    if True in subd['label'].unique():\n",
    "        attack_real += 1\n",
    "        subd_attacked.append(subd)\n",
    "        mi_attacked.append(predict_result)\n",
    "    \n",
    "    if predict_result.any().any():\n",
    "        attack_predict += 1\n",
    "    \n",
    "print(f\"Total: {total}\")\n",
    "print(f\"Attack real: {attack_real}\")\n",
    "print(f\"Attack predict: {attack_predict}\")\n",
    "print(f\"Accuracy: {attack_predict/total}\")\n",
    "print(f\"Recall: {attack_predict/attack_real}\")\n",
    "print(f\"Precision: {attack_predict/(attack_predict + (total - attack_real))}\")\n",
    "print(f\"F1 score: {2 * (attack_predict/(attack_predict + (total - attack_real))) * (attack_predict/attack_real) / ((attack_predict/(attack_predict + (total - attack_real))) + (attack_predict/attack_real))}\")\n",
    "display(subd_attacked, mi_attacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mi_attacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203890, 1507952.7333333334)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal_1 = pd.concat(df_normal)\n",
    "len(sub_dfs), len(df_normal_1)/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = df_attack.loc[(df_attack['label'] == True) & (df_attack['aid'] == 1255) & (df_attack['time_diffs'] < 0.2)]\n",
    "\n",
    "sum_time = df_all.groupby(['aid', 'label']).agg({'data': ['count']})\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(sum_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>aid</th>\n",
       "      <th>data</th>\n",
       "      <th>ori_time</th>\n",
       "      <th>time_diffs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>1.618163</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>2.618064</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>3.617806</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11049</th>\n",
       "      <td>4.617810</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>1.000004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13441</th>\n",
       "      <td>5.618164</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>1.000354</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113058</th>\n",
       "      <td>47.280774</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077B90C2C000</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113297</th>\n",
       "      <td>47.381792</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077B10C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113533</th>\n",
       "      <td>47.481730</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077990C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113783</th>\n",
       "      <td>47.581725</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077AD0C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099995</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114024</th>\n",
       "      <td>47.680661</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077AB0C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.098936</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25614610 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   aid              data      ori_time  time_diffs  label\n",
       "3873     1.618163     6  0800006400000000  1.030000e+09    0.999845  False\n",
       "6266     2.618064     6  0800006400000000  1.030000e+09    0.999901  False\n",
       "8655     3.617806     6  0800006400000000  1.030000e+09    0.999742  False\n",
       "11049    4.617810     6  0800006400000000  1.030000e+09    1.000004  False\n",
       "13441    5.618164     6  0800006400000000  1.030000e+09    1.000354  False\n",
       "...           ...   ...               ...           ...         ...    ...\n",
       "113058  47.280774  1788  0000077B90C2C000  1.050000e+09    0.099978  False\n",
       "113297  47.381792  1788  0000077B10C2B800  1.050000e+09    0.101018  False\n",
       "113533  47.481730  1788  0000077990C2B800  1.050000e+09    0.099938  False\n",
       "113783  47.581725  1788  0000077AD0C2B800  1.050000e+09    0.099995  False\n",
       "114024  47.680661  1788  0000077AB0C2B800  1.050000e+09    0.098936  False\n",
       "\n",
       "[25614610 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all_normal = df_all[df_all['label'] == False]\n",
    "display(df_all_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>aid</th>\n",
       "      <th>data</th>\n",
       "      <th>ori_time</th>\n",
       "      <th>time_diffs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006927</td>\n",
       "      <td>167</td>\n",
       "      <td>0010FA27012B90A0</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.008660</td>\n",
       "      <td>1760</td>\n",
       "      <td>015D015D01560159</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008952</td>\n",
       "      <td>293</td>\n",
       "      <td>90002DDF20383F60</td>\n",
       "      <td>1.200000e+09</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008952</td>\n",
       "      <td>293</td>\n",
       "      <td>90002DDF20383F60</td>\n",
       "      <td>1.170000e+09</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.009104</td>\n",
       "      <td>208</td>\n",
       "      <td>6A710460EF000000</td>\n",
       "      <td>1.190000e+09</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821908</th>\n",
       "      <td>3764.315521</td>\n",
       "      <td>1076</td>\n",
       "      <td>030AA0A8D194B6B0</td>\n",
       "      <td>1.110004e+09</td>\n",
       "      <td>0.019963</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821909</th>\n",
       "      <td>3764.315522</td>\n",
       "      <td>1760</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>1.110004e+09</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821910</th>\n",
       "      <td>3764.315522</td>\n",
       "      <td>192</td>\n",
       "      <td>6000000000000000</td>\n",
       "      <td>1.110004e+09</td>\n",
       "      <td>0.018924</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821911</th>\n",
       "      <td>3764.316567</td>\n",
       "      <td>1644</td>\n",
       "      <td>0080100020000020</td>\n",
       "      <td>1.110004e+09</td>\n",
       "      <td>0.099955</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821912</th>\n",
       "      <td>3764.316568</td>\n",
       "      <td>1176</td>\n",
       "      <td>87FFBFFCF6800006</td>\n",
       "      <td>1.110004e+09</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25614610 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time   aid              data      ori_time  time_diffs  label\n",
       "16          0.006927   167  0010FA27012B90A0  1.030000e+09    0.006927  False\n",
       "18          0.008660  1760  015D015D01560159  1.000000e+09    0.007658  False\n",
       "26          0.008952   293  90002DDF20383F60  1.200000e+09    0.008952  False\n",
       "26          0.008952   293  90002DDF20383F60  1.170000e+09    0.008952  False\n",
       "25          0.009104   208  6A710460EF000000  1.190000e+09    0.009104  False\n",
       "...              ...   ...               ...           ...         ...    ...\n",
       "8821908  3764.315521  1076  030AA0A8D194B6B0  1.110004e+09    0.019963  False\n",
       "8821909  3764.315522  1760  0000000000000000  1.110004e+09    0.013771  False\n",
       "8821910  3764.315522   192  6000000000000000  1.110004e+09    0.018924  False\n",
       "8821911  3764.316567  1644  0080100020000020  1.110004e+09    0.099955  False\n",
       "8821912  3764.316568  1176  87FFBFFCF6800006  1.110004e+09    0.019964  False\n",
       "\n",
       "[25614610 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sorted = df_all_normal.sort_values(by=['time'])\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>aid</th>\n",
       "      <th>data</th>\n",
       "      <th>ori_time</th>\n",
       "      <th>time_diffs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>1.618163</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.014802</td>\n",
       "      <td>14</td>\n",
       "      <td>205296020809767A</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.024708</td>\n",
       "      <td>14</td>\n",
       "      <td>2052960208097674</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.054923</td>\n",
       "      <td>14</td>\n",
       "      <td>205296020809766E</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.104714</td>\n",
       "      <td>14</td>\n",
       "      <td>2052960208097680</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112587</th>\n",
       "      <td>47.080794</td>\n",
       "      <td>1788</td>\n",
       "      <td>00000779F0C2C000</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099962</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113058</th>\n",
       "      <td>47.280774</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077B90C2C000</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113297</th>\n",
       "      <td>47.381792</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077B10C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113533</th>\n",
       "      <td>47.481730</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077990C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113783</th>\n",
       "      <td>47.581725</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077AD0C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099995</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4325955 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   aid              data      ori_time  time_diffs  label\n",
       "3873     1.618163     6  0800006400000000  1.030000e+09    0.999845  False\n",
       "33       0.014802    14  205296020809767A  1.030000e+09    0.009998  False\n",
       "54       0.024708    14  2052960208097674  1.030000e+09    0.009906  False\n",
       "128      0.054923    14  205296020809766E  1.030000e+09    0.010121  False\n",
       "243      0.104714    14  2052960208097680  1.030000e+09    0.009938  False\n",
       "...           ...   ...               ...           ...         ...    ...\n",
       "112587  47.080794  1788  00000779F0C2C000  1.050000e+09    0.099962  False\n",
       "113058  47.280774  1788  0000077B90C2C000  1.050000e+09    0.099978  False\n",
       "113297  47.381792  1788  0000077B10C2B800  1.050000e+09    0.101018  False\n",
       "113533  47.481730  1788  0000077990C2B800  1.050000e+09    0.099938  False\n",
       "113783  47.581725  1788  0000077AD0C2B800  1.050000e+09    0.099995  False\n",
       "\n",
       "[4325955 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_unique = df_all.drop_duplicates(subset=['aid', 'data'])\n",
    "display(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique = df_unique.groupby(['aid', 'label']).agg({'data': ['count']})\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(data_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>aid</th>\n",
       "      <th>data</th>\n",
       "      <th>ori_time</th>\n",
       "      <th>time_diffs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>1.618163</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>2.618064</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>3.617806</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11049</th>\n",
       "      <td>4.617810</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>1.000004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13441</th>\n",
       "      <td>5.618164</td>\n",
       "      <td>6</td>\n",
       "      <td>0800006400000000</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>1.000354</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113058</th>\n",
       "      <td>47.280774</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077B90C2C000</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113297</th>\n",
       "      <td>47.381792</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077B10C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113533</th>\n",
       "      <td>47.481730</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077990C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099938</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113783</th>\n",
       "      <td>47.581725</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077AD0C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.099995</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114024</th>\n",
       "      <td>47.680661</td>\n",
       "      <td>1788</td>\n",
       "      <td>0000077AB0C2B800</td>\n",
       "      <td>1.050000e+09</td>\n",
       "      <td>0.098936</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25677443 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   aid              data      ori_time  time_diffs  label\n",
       "3873     1.618163     6  0800006400000000  1.030000e+09    0.999845  False\n",
       "6266     2.618064     6  0800006400000000  1.030000e+09    0.999901  False\n",
       "8655     3.617806     6  0800006400000000  1.030000e+09    0.999742  False\n",
       "11049    4.617810     6  0800006400000000  1.030000e+09    1.000004  False\n",
       "13441    5.618164     6  0800006400000000  1.030000e+09    1.000354  False\n",
       "...           ...   ...               ...           ...         ...    ...\n",
       "113058  47.280774  1788  0000077B90C2C000  1.050000e+09    0.099978  False\n",
       "113297  47.381792  1788  0000077B10C2B800  1.050000e+09    0.101018  False\n",
       "113533  47.481730  1788  0000077990C2B800  1.050000e+09    0.099938  False\n",
       "113783  47.581725  1788  0000077AD0C2B800  1.050000e+09    0.099995  False\n",
       "114024  47.680661  1788  0000077AB0C2B800  1.050000e+09    0.098936  False\n",
       "\n",
       "[25677443 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "display(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_column(row):\n",
    "    data = row['data']\n",
    "    chunks = [data[i:i+2] for i in range(0, len(data), 2)]\n",
    "    return pd.Series(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_208 = pd.DataFrame({})\n",
    "df_208[['data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8']] = df_unique[(df_unique['aid'] == 1760) & (df_unique['label'] == True)].apply(split_data_column, axis=1)\n",
    "df_208.to_csv('aid_1760.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>aid</th>\n",
       "      <th>data</th>\n",
       "      <th>ori_time</th>\n",
       "      <th>time_diffs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21990</th>\n",
       "      <td>9.190831</td>\n",
       "      <td>1760</td>\n",
       "      <td>595945450000FFFF</td>\n",
       "      <td>1.030000e+09</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18760</th>\n",
       "      <td>7.611744</td>\n",
       "      <td>1760</td>\n",
       "      <td>FFFFFFFFFFFFFFFF</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time   aid              data      ori_time  time_diffs  label\n",
       "21990  9.190831  1760  595945450000FFFF  1.030000e+09    0.003063   True\n",
       "18760  7.611744  1760  FFFFFFFFFFFFFFFF  1.000000e+09    0.004122   True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique[(df_unique['aid'] == 1760) & (df_unique['label'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the amount of data per aid\n",
    "amount_data_per_aid = df_all_normal.groupby('aid').size()\n",
    "\n",
    "# Extract max and min time_diffs per aid\n",
    "max_time_diffs_per_aid = df_all_normal.groupby('aid')['time_diffs'].max()\n",
    "min_time_diffs_per_aid = df_all_normal.groupby('aid')['time_diffs'].min()\n",
    "\n",
    "def find_common_pattern(strings):\n",
    "    # Convert the first string to a NumPy array\n",
    "    common_pattern = np.array(list(strings[0]))\n",
    "    \n",
    "    # Iterate through the rest of the strings\n",
    "    for string in strings[1:]:\n",
    "        # Convert the string to a NumPy array\n",
    "        arr = np.array(list(string))\n",
    "        \n",
    "        # Update the common pattern using vectorized operations\n",
    "        common_pattern[arr != common_pattern] = 'X'\n",
    "    \n",
    "    # Convert the NumPy array back to a string\n",
    "    result = ''.join(common_pattern)\n",
    "\n",
    "    return result\n",
    "\n",
    "for aid in amount_data_per_aid.keys():\n",
    "    print(f\"\\ncanid {aid} have {amount_data_per_aid[aid]}\")\n",
    "    print(f\"max time diff {max_time_diffs_per_aid[aid]} and min time diff {min_time_diffs_per_aid[aid]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_mi': 3.906890595608518,\n",
       " 'min_mi': 1.7464657985040721,\n",
       " 'max_en_x': 3.906890595608518,\n",
       " 'min_en_x': 1.7464657985040721,\n",
       " 'max_en_y': 3.906890595608518,\n",
       " 'min_en_y': 1.9628066316931743,\n",
       " 'max_en_y_x': 0.7999999999999999,\n",
       " 'min_en_y_x': 0.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# display(pattern_dict)\n",
    "display(rule_entropy_dict)\n",
    "rule_all_dict = copy.copy(rule_entropy_dict)\n",
    "\n",
    "for aid in amount_data_per_aid.keys():\n",
    "    rule_all_dict[aid] = {\"max_time\": max_time_diffs_per_aid[aid], \"min_time\": min_time_diffs_per_aid[aid], \"pattern\": pattern_dict[str(aid)]}\n",
    "\n",
    "with open('/home/tiendat/transformer-entropy-ids/rule_all_dict.json', 'w+') as fp:\n",
    "    json.dump(rule_all_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = [   6,   14,   37,   51,   58,   60,   61,   65,  117,  167,  186,\n",
    "        192,  204,  208,  215,  241,  244,  248,  253,  263,  293,  300,\n",
    "        304,  339,  354,  403,  412,  420,  426,  452,  458,  470,  485,\n",
    "        519,  526,  541,  560,  569,  622,  627,  628,  631,  640,  651,\n",
    "        661,  663,  675,  676,  683,  692,  695,  705,  722,  727,  737,\n",
    "        738,  778,  813,  837,  852,  870,  881,  930,  953,  961,  996,\n",
    "       1031, 1049, 1072, 1076, 1124, 1175, 1176, 1225, 1227, 1255, 1262,\n",
    "       1277, 1307, 1314, 1331, 1372, 1398, 1399, 1408, 1413, 1455, 1459,\n",
    "       1505, 1512, 1533, 1560, 1590, 1621, 1628, 1634, 1644, 1649, 1661,\n",
    "       1668, 1693, 1694, 1751, 1760, 1788]\n",
    "\n",
    "# parttern = [find_common_pattern(list(df_all.groupby('aid')['data']))]\n",
    "grouped_data = df_unique.groupby('aid')['data'].apply(list).reset_index()\n",
    "# grouped_data['pattern'] = grouped_data['data'].apply(lambda x: find_common_pattern(x))\n",
    "# for aid in key:\n",
    "#     # print(f\"max time diff {max_time_diffs_per_aid[aid]} and min time diff {min_time_diffs_per_aid[aid]} ===========================================\")\n",
    "#     if df_all[df_all['aid'] == aid].shape[0] >= 20 and df_all[df_all['aid'] == aid].shape[0] <= 50:    \n",
    "#        print(f\"{aid}\")\n",
    "#        display(df_all[df_all['aid'] == aid]['data'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_all.groupby('aid')['data'].apply(lambda x: find_common_pattern(x))\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0X0000XX00000000\n",
      "1      20XXX602080XXXXX\n",
      "2      0000XXX840XXXXX1\n",
      "3      XXXXXXXXXXXXXXX0\n",
      "4      0000000000XXXX00\n",
      "             ...       \n",
      "100    XXXXXXX0XXXXXXXX\n",
      "101    XX400XXXXXX0XXXX\n",
      "102    XXXXXX0XX0XXXXXX\n",
      "103    XXXXXXXXXXXXXXXX\n",
      "104    X000XXXXXXXXXXXX\n",
      "Name: pattern, Length: 105, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the option to display all rows and columns\n",
    "pd.set_option(\"display.max_rows\", 15)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(grouped_data['pattern'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_entropy_ver2(X):\n",
    "    p_x = defaultdict(float)\n",
    "    n = len(X)\n",
    "    \n",
    "    for x in X:\n",
    "        p_x[x] += 1 / n\n",
    "    \n",
    "    H_X = 0\n",
    "    for x in p_x:\n",
    "        H_X += -p_x[x] * np.log2(p_x[x])\n",
    "    return H_X\n",
    "\n",
    "def calculate_conditional_entropy_ver2(X, Y):\n",
    "    p_x = defaultdict(float)\n",
    "    p_y_given_x = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    n = len(X)\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        p_x[x] += 1 / n\n",
    "        p_y_given_x[x][y] += 1\n",
    "    \n",
    "    for x in p_y_given_x:\n",
    "        total = sum(p_y_given_x[x].values())\n",
    "        for y in p_y_given_x[x]:\n",
    "            p_y_given_x[x][y] /= total\n",
    "    \n",
    "    H_Y_given_X = 0\n",
    "    for x in p_x:\n",
    "        for y in p_y_given_x[x]:\n",
    "            H_Y_given_X += p_x[x] * p_y_given_x[x][y] * -np.log2(p_y_given_x[x][y])\n",
    "    \n",
    "    return H_Y_given_X\n",
    "\n",
    "def calculate_mutual_information(df):\n",
    "    X = df['aid']\n",
    "    Y = df['data']\n",
    "    H_X = calculate_entropy(X)\n",
    "    H_Y = calculate_entropy(Y)\n",
    "    H_Y_given_X = calculate_conditional_entropy(X, Y)\n",
    "    \n",
    "    I_X_Y = H_Y - H_Y_given_X\n",
    "    return I_X_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subd in sub_dfs:\n",
    "    if subd['aid'].unique()[0] == 1760:\n",
    "        print(subd['data'].unique())\n",
    "        print(calculate_entropy_ver2(subd['data'].unique()))\n",
    "        print(calculate_mutual_information(subd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.002415895462036133\n",
      "aid\n",
      "14      0.0\n",
      "51      0.0\n",
      "61      0.0\n",
      "167     0.0\n",
      "186     0.0\n",
      "208     0.0\n",
      "263     0.0\n",
      "293     0.0\n",
      "651     0.0\n",
      "852     0.0\n",
      "961     0.0\n",
      "1413    0.0\n",
      "1505    0.0\n",
      "1760    0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mtime_start\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(list_entropy)\n\u001b[0;32m----> 6\u001b[0m aa\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "for subd in sub_dfs:\n",
    "    time_start = time.time()\n",
    "    list_entropy = subd.groupby('aid').apply(calculate_mutual_information)\n",
    "    print(f\"Time: {time.time() - time_start}\")\n",
    "    print(list_entropy)\n",
    "    aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.75"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mutual_information('03B103AB03A403A4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define the Regex method\n",
    "def match_pattern_regex(string, pattern):\n",
    "    regex_pattern = pattern.replace('X', '.')\n",
    "    return bool(re.fullmatch(regex_pattern, string))\n",
    "\n",
    "def extract_X_positions(payload, pattern):\n",
    "    extracted_chars = [payload[i] for i, char in enumerate(pattern) if char == 'X']\n",
    "    return ''.join(extracted_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing the required libraries and re-running the payload_to_dataframe function\n",
    "import pandas as pd\n",
    "# Re-define the function to calculate Mutual Information, as the code state was reset\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "def calculate_mutual_information(df):\n",
    "    # Calculate the joint probability distribution p(x, y)\n",
    "    joint_prob = Counter(zip(df['X'], df['Y']))\n",
    "    total_count = len(df)\n",
    "    joint_prob = {key: value / total_count for key, value in joint_prob.items()}\n",
    "\n",
    "    # Calculate the marginal probabilities p(x) and p(y)\n",
    "    prob_x = Counter(df['X'])\n",
    "    prob_y = Counter(df['Y'])\n",
    "    prob_x = {key: value / total_count for key, value in prob_x.items()}\n",
    "    prob_y = {key: value / total_count for key, value in prob_y.items()}\n",
    "    \n",
    "    # Calculate Mutual Information I(X;Y)\n",
    "    mutual_info = 0\n",
    "    for (x, y), p_xy in joint_prob.items():\n",
    "        p_x = prob_x.get(x, 0)\n",
    "        p_y = prob_y.get(y, 0)\n",
    "        \n",
    "        if p_x > 0 and p_y > 0:\n",
    "            mutual_info += p_xy * log2(p_xy / (p_x * p_y))\n",
    "    \n",
    "    return mutual_info\n",
    "\n",
    "\n",
    "# Function to convert payload into a DataFrame containing columns X and Y\n",
    "def payload_to_dataframe(payload):\n",
    "    # Split the payload into X and Y parts\n",
    "    X_values = [payload[i:i+1] for i in range(0, len(payload)//2, 1)]\n",
    "    Y_values = [payload[i:i+1] for i in range(len(payload)//2, len(payload), 1)]\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'X': X_values,\n",
    "        'Y': Y_values\n",
    "    })\n",
    "    \n",
    "    return calculate_mutual_information(df)\n",
    "\n",
    "def calculate_conditional_entropy(string):\n",
    "    X = string[0:8]\n",
    "    Y = string[8:16]\n",
    "    p_x = defaultdict(float)\n",
    "    p_y_given_x = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    n = len(X)\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        p_x[x] += 1 / n\n",
    "        p_y_given_x[x][y] += 1\n",
    "    \n",
    "    for x in p_y_given_x:\n",
    "        total = sum(p_y_given_x[x].values())\n",
    "        for y in p_y_given_x[x]:\n",
    "            p_y_given_x[x][y] /= total\n",
    "    \n",
    "    H_Y_given_X = 0\n",
    "    for x in p_x:\n",
    "        for y in p_y_given_x[x]:\n",
    "            H_Y_given_X += p_x[x] * p_y_given_x[x][y] * -np.log2(p_y_given_x[x][y])\n",
    "    \n",
    "    return H_Y_given_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mutual_information('595945450000FFFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2894134/2099272133.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1255_normal['mi'] = df_1255_normal['data'].apply(lambda x: calculate_conditional_entropy(x))\n"
     ]
    }
   ],
   "source": [
    "df_1255_normal = df_unique[df_unique['aid'] == 1760]\n",
    "# df_1255_attack = df_attack[df_attack['aid'] == 1760]\n",
    "\n",
    "df_1255_normal['mi'] = df_1255_normal['data'].apply(lambda x: calculate_conditional_entropy(x))\n",
    "# df_1255_attack['mi'] = df_1255_attack['data'].apply(lambda x: payload_to_dataframe(x))\n",
    "print(df_1255_normal['mi'].min(), df_1255_normal['mi'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'include'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2894134/1290512425.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1255_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_1255_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'138C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/torchtf/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'include'"
     ]
    }
   ],
   "source": [
    "display(df_1255_attack[df_1255_attack['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "# Generate a synthetic dataset for demonstration\n",
    "# Assuming CanID is an integer < 2000 and Data is a 16-character hexadecimal string\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Split the 'Data' column into two separate columns for X and Y\n",
    "df_sorted['X'] = df_sorted['data'].apply(lambda x: x[:8])\n",
    "df_sorted['Y'] = df_sorted['data'].apply(lambda x: x[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "# Function to calculate Conditional Mutual Information for a given DataFrame\n",
    "def calculate_CMI(df):\n",
    "    # Calculate the joint probability distribution p(x, y, z)\n",
    "    joint_prob = Counter(zip(df['X'], df['Y'], df['aid']))\n",
    "    total_count = len(df)\n",
    "    joint_prob = {key: value / total_count for key, value in joint_prob.items()}\n",
    "\n",
    "    # Initialize variables to hold conditional probabilities and sums\n",
    "    cond_prob_x_given_z = {}\n",
    "    cond_prob_y_given_z = {}\n",
    "    cond_prob_xy_given_z = {}\n",
    "    sum_prob_given_z = Counter(df['aid'])\n",
    "\n",
    "    # Calculate conditional probabilities\n",
    "    for (x, y, z), p_xyz in joint_prob.items():\n",
    "        sum_z = sum_prob_given_z[z] / total_count\n",
    "        cond_prob_x_given_z[(x, z)] = p_xyz / sum_z if sum_z > 0 else 0\n",
    "        cond_prob_y_given_z[(y, z)] = p_xyz / sum_z if sum_z > 0 else 0\n",
    "        cond_prob_xy_given_z[(x, y, z)] = p_xyz / sum_z if sum_z > 0 else 0\n",
    "\n",
    "    # Calculate Conditional Mutual Information (CMI)\n",
    "    CMI = 0\n",
    "    for (x, y, z), p_xyz in joint_prob.items():\n",
    "        pxz = cond_prob_x_given_z.get((x, z), 0)\n",
    "        pyz = cond_prob_y_given_z.get((y, z), 0)\n",
    "        pxyz = cond_prob_xy_given_z.get((x, y, z), 0)\n",
    "        \n",
    "        if pxz > 0 and pyz > 0 and pxyz > 0:\n",
    "            CMI += p_xyz * log2(pxyz / (pxz * pyz))\n",
    "    \n",
    "    return CMI\n",
    "\n",
    "# Calculate CMI for each set of 15 rows in the DataFrame\n",
    "CMI_values = []\n",
    "for i in range(0, len(df_sorted), 15):\n",
    "    if len(df_sorted) - i < 15:\n",
    "        subset_df = df_sorted.iloc[i:len(df_sorted) - 1]\n",
    "        CMI_values.append(calculate_CMI(subset_df))\n",
    "    else:\n",
    "        subset_df = df_sorted.iloc[i:i+15]\n",
    "        CMI_values.append(calculate_CMI(subset_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMI_values_attack = [] \n",
    "df_attack['X'] = df_attack['data'].apply(lambda x: x[:8])\n",
    "df_attack['Y'] = df_attack['data'].apply(lambda x: x[8:])\n",
    "for i in range(0, len(df_attack), 15):\n",
    "    if len(df_attack) - i < 15:\n",
    "        subset_df = df_attack.iloc[i:len(df_attack) - 1]\n",
    "        CMI_values_attack.append(calculate_CMI(subset_df))\n",
    "    else:\n",
    "        subset_df = df_sorted.iloc[i:i+15]\n",
    "        CMI_values_attack.append(calculate_CMI(subset_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203876 3.4594316186372978\n"
     ]
    }
   ],
   "source": [
    "max(CMI_values_attack)\n",
    "count = 0\n",
    "for index, value in enumerate(CMI_values_attack):\n",
    "    if value > 1.7249535320618146:\n",
    "        print(index, value)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4594316186372978"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(CMI_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
